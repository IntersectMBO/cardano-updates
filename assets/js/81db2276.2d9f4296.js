"use strict";(self.webpackChunkcardano_updates=self.webpackChunkcardano_updates||[]).push([[81360],{3905:(e,n,t)=>{t.d(n,{Zo:()=>p,kt:()=>h});var r=t(67294);function a(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function o(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);n&&(r=r.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,r)}return t}function i(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?o(Object(t),!0).forEach((function(n){a(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):o(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function l(e,n){if(null==e)return{};var t,r,a=function(e,n){if(null==e)return{};var t,r,a={},o=Object.keys(e);for(r=0;r<o.length;r++)t=o[r],n.indexOf(t)>=0||(a[t]=e[t]);return a}(e,n);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(r=0;r<o.length;r++)t=o[r],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(a[t]=e[t])}return a}var s=r.createContext({}),c=function(e){var n=r.useContext(s),t=n;return e&&(t="function"==typeof e?e(n):i(i({},n),e)),t},p=function(e){var n=c(e.components);return r.createElement(s.Provider,{value:n},e.children)},d="mdxType",m={inlineCode:"code",wrapper:function(e){var n=e.children;return r.createElement(r.Fragment,{},n)}},u=r.forwardRef((function(e,n){var t=e.components,a=e.mdxType,o=e.originalType,s=e.parentName,p=l(e,["components","mdxType","originalType","parentName"]),d=c(t),u=a,h=d["".concat(s,".").concat(u)]||d[u]||m[u]||o;return t?r.createElement(h,i(i({ref:n},p),{},{components:t})):r.createElement(h,i({ref:n},p))}));function h(e,n){var t=arguments,a=n&&n.mdxType;if("string"==typeof e||a){var o=t.length,i=new Array(o);i[0]=u;var l={};for(var s in n)hasOwnProperty.call(n,s)&&(l[s]=n[s]);l.originalType=e,l[d]="string"==typeof e?e:a,i[1]=l;for(var c=2;c<o;c++)i[c]=t[c];return r.createElement.apply(null,i)}return r.createElement.apply(null,t)}u.displayName="MDXCreateElement"},57779:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>s,contentTitle:()=>i,default:()=>m,frontMatter:()=>o,metadata:()=>l,toc:()=>c});var r=t(87462),a=(t(67294),t(3905));const o={title:"Performance & Tracing Update",slug:"2024-02-16-performance-and-tracing",authors:"mgmeier",tags:["performance-tracing"],hide_table_of_contents:!1},i=void 0,l={permalink:"/2024-02-16-performance-and-tracing",editUrl:"https://github.com/intersectmbo/cardano-updates/tree/main/blog/2024-02-16-performance-and-tracing.md",source:"@site/blog/2024-02-16-performance-and-tracing.md",title:"Performance & Tracing Update",description:"High level summary",date:"2024-02-16T00:00:00.000Z",formattedDate:"February 16, 2024",tags:[{label:"performance-tracing",permalink:"/tags/performance-tracing"}],readingTime:2.97,hasTruncateMarker:!1,authors:[{name:"Michael Karg",title:"Performance and Tracing Team Lead",url:"https://github.com/mgmeier",imageURL:"https://github.com/mgmeier.png",key:"mgmeier"}],frontMatter:{title:"Performance & Tracing Update",slug:"2024-02-16-performance-and-tracing",authors:"mgmeier",tags:["performance-tracing"],hide_table_of_contents:!1},prevItem:{title:"Hydra Team Update",permalink:"/2024-02-16-hydra"},nextItem:{title:"SRE Team Update",permalink:"/2024-02-16-sre"}},s={authorsImageUrls:[void 0]},c=[{value:"High level summary",id:"high-level-summary",level:2},{value:"Low level overview",id:"low-level-overview",level:2},{value:"Benchmarking",id:"benchmarking",level:3},{value:"Performance",id:"performance",level:3},{value:"Development",id:"development",level:3},{value:"Workbench",id:"workbench",level:3},{value:"Tracing",id:"tracing",level:3},{value:"Nomad backend",id:"nomad-backend",level:3}],p={toc:c},d="wrapper";function m(e){let{components:n,...t}=e;return(0,a.kt)(d,(0,r.Z)({},p,t,{components:n,mdxType:"MDXLayout"}),(0,a.kt)("h2",{id:"high-level-summary"},"High level summary"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Benchmarking: Release benchmarks for ",(0,a.kt)("inlineCode",{parentName:"li"},"8.8.0")," have been performed; we created a local repro for a residual issue."),(0,a.kt)("li",{parentName:"ul"},"Performance: We've implemented and benchmarked two candidates investigating residual issues with GHC9.6."),(0,a.kt)("li",{parentName:"ul"},"Development: Work on the reporting pipeline is ongoing; integration of ",(0,a.kt)("inlineCode",{parentName:"li"},"DRep"),"s into benchmarking workloads has begun."),(0,a.kt)("li",{parentName:"ul"},"Workbench: Implementation of high-level profile definition is ongoing. "),(0,a.kt)("li",{parentName:"ul"},"Tracing: The handle registry feature for ",(0,a.kt)("inlineCode",{parentName:"li"},"cardano-tracer")," is completed; currently in testing."),(0,a.kt)("li",{parentName:"ul"},"Nomad cluster: Increased robustness of deployment and run monitoring has been merged; work on garbage collection has started.")),(0,a.kt)("h2",{id:"low-level-overview"},"Low level overview"),(0,a.kt)("h3",{id:"benchmarking"},"Benchmarking"),(0,a.kt)("p",null,"We've performed a full set of release benchmarks for Node ",(0,a.kt)("inlineCode",{parentName:"p"},"8.8.0-pre"),". Comparing with release ",(0,a.kt)("inlineCode",{parentName:"p"},"8.7.2"),", we could\nnot detect any performance risks for that version. We even saw a slight improvement in block fetch related metrics, which led to slightly improved block diffusion times.  "),(0,a.kt)("p",null,"Furthermore, we've managed to boil down a complex residual performance issue measured on the cluster to a local reproduction. This enables our DevX team, with highly specialized knowledge of GHC's compiler internals, to\ninvestigate each step in code generation and optimzation, and independently observe the effects of code changes to the affected component."),(0,a.kt)("h3",{id:"performance"},"Performance"),(0,a.kt)("p",null,"Work on the remaining performance issue with GHC9.6 led us to produce two candidates based on Node ",(0,a.kt)("inlineCode",{parentName:"p"},"8.7.2"),", benchmarking\nthe implacations local small changes have for GHC9.6's optimizer. Though those candidates did not uncover the\nissue's root cause, they were able to disprove a hypothesis as to its nature, and quantify the performance impact of said small changes."),(0,a.kt)("h3",{id:"development"},"Development"),(0,a.kt)("p",null,"Node ",(0,a.kt)("inlineCode",{parentName:"p"},"8.8.0")," comes with capabilities to inject ",(0,a.kt)("inlineCode",{parentName:"p"},"DRep"),"s and ",(0,a.kt)("inlineCode",{parentName:"p"},"DRep")," delegations into Conway genesis. We've started work\non integrating those into our automations, and setting sensible values for benchmarking. The aforementioned\ndelegations representing a new data structure in the Conway ledger, we aim to run\nexisting workflows extended with varying sizes of that new structure, measuring their pressure on ledger queries and operations."),(0,a.kt)("h3",{id:"workbench"},"Workbench"),(0,a.kt)("p",null,"The performance workbench relies heavily on shell scripting and manipulating JSON data for a great part of its features. This approach\nis very effective for quick experimentation, but lacks in verifiable properties as well as accessibility for new users of workbench."),(0,a.kt)("p",null,"After the successful Haskell port of cluster topology creation, and verification, we're currently applying\nthe same model in porting the entirety of benchmarking profiles to Haskell. The obvious gains are widening workbench's\naudience both for users and developers, as well as implementing a principled approach to all workbench data structures and transformations.  "),(0,a.kt)("p",null,"At the same time, we're porting workbench's many options to create fine-tuned geneses, following the same approach."),(0,a.kt)("h3",{id:"tracing"},"Tracing"),(0,a.kt)("p",null,"We've outfitted ",(0,a.kt)("inlineCode",{parentName:"p"},"cardano-tracer")," with a handle registry feature that lets the service work on file handles internally, rather than opening and closing files for each operation. The feature is completed; at the moment we're adding\nappropriate test cases to the service's test suite for validation of its behaviour, and for safeguarding future development."),(0,a.kt)("h3",{id:"nomad-backend"},"Nomad backend"),(0,a.kt)("p",null,"Several improvements for our cluster backend have been merged to ",(0,a.kt)("inlineCode",{parentName:"p"},"master"),", increasing its overall robustness. We can now safely handle some corner cases where Nomad processes unexpectedly exited, or deployments errored out. Furthermore, an ongoing\nrun can now reliably survive a temporary loss of heartbeat connection between Nomad client and server, without\nthe benchmarking metrics being affected.  "),(0,a.kt)("p",null,"Currently, we're working on a reliable automation of garbage collecting old ",(0,a.kt)("inlineCode",{parentName:"p"},"nix")," store entries on the cluster machines, as they fill up disk space. The design has to consider both not interfering with ongoing benchmarks, and\navoiding deployment overhead caused by cleaning the store too frequently."))}m.isMDXComponent=!0}}]);