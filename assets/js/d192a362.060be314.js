"use strict";(self.webpackChunkcardano_updates=self.webpackChunkcardano_updates||[]).push([[28810],{42013:e=>{e.exports=JSON.parse('{"blogPosts":[{"id":"2025-07-performance-10.5.0","metadata":{"permalink":"/reports/2025-07-performance-10.5.0","editUrl":"https://github.com/intersectmbo/cardano-updates/tree/main/reports/2025-07-performance-10.5.0.md","source":"@site/reports/2025-07-performance-10.5.0.md","title":"Benchmarking -- Node 10.5.0","description":"Setup","date":"2025-07-02T09:50:10.000Z","formattedDate":"July 2, 2025","tags":[{"label":"benchmarking-reports","permalink":"/reports/tags/benchmarking-reports"}],"readingTime":3.35,"hasTruncateMarker":false,"authors":[{"name":"Michael Karg","title":"Performance and Tracing Team Lead","url":"https://github.com/mgmeier","imageURL":"https://github.com/mgmeier.png","key":"mgmeier"}],"frontMatter":{"title":"Benchmarking -- Node 10.5.0","slug":"2025-07-performance-10.5.0","authors":"mgmeier","tags":["benchmarking-reports"],"hide_table_of_contents":false},"nextItem":{"title":"Benchmarking -- Node 10.4.1","permalink":"/reports/2025-05-performance-10.4.1"}},"content":"## Setup\\n\\nAs part of the release benchmarking cycle, we\'re comparing benchmarking runs for 2 different versions of `cardano-node`:\\n* `10.4.1` - baseline from the previous Node release\\n* `10.5.0` - the current (pre-)release tag\\n\\nFor this benchmark, we\'re gathering various metrics under 2 different workloads:\\n1. _value-only_: Each transaction consumes 2 inputs and creates 2 outputs, changing the UTxO set. This workload produces full blocks (> 80kB) exclusively.\\n2. _Plutus_: Each transaction contains a Plutus script exhausting the per-tx execution budget. This workload produces small blocks (< 3kB) exclusively.\\n\\nBenchmarking is performed on a cluster of 52 block producing nodes spread across 3 different AWS regions, interconnected using a static, restricted topology. All runs\\nwere performed in the Conway era.  \\n\\n## Preliminaries\\n\\n1. The feature in `10.5` with major performance impact is periodic [ledger metrics]. This is exclusive to the [new tracing system].\\n2. `10.5` flips the default config for `PeerSharing` to `true`; however, the recommendation is to explicitly set it to `false` on block producers. If not for privacy issues alone, we also found disadvantageous performance impact on block production when enabled. Hence, our benchmarks do not factor in that overhead.\\n\\n## Observations\\n\\nThese benchmarks are about evaluating specific corner cases in a constrained environment that allows for reliable reproduction of results; they\'re not trying to directly recreate the operational conditions on Mainnet.  \\n\\n### Resource Usage\\n\\n1. `10.5.0` shows a clear reduction in CPU usage - by ~30% regardless of workload type.\\n2. Furthermore, Allocation rate and GC impact are clearly reduced - by 27%-29% and 24%-25% respectively.\\n3. Heap size _increases_ very slightly under saturation (by 1%) and _decreases_ very slightly (by 1%) under Plutus workload.\\n4. CPU 85% spans are slightly _shorter_ (~0.2 slots) under saturation, and slightly _longer_ (~0.26 slots) under Plutus workload.\\n\\nCaveat: Individual metrics can\'t be evaluated in isolate; the resource usage profile as a whole provides insight into the system\'s performance and responsiveness.\\n\\n### Forging Loop\\n\\n1. Block Context Acquisition time (prior to leadership check) is greatly reduced - from ~24ms to under 1ms.\\n2. Under saturation only, Ledger Ticking and Mempool Snapshotting exhibit very slight upticks (by 3ms and 2ms respectively).\\n3. Under Plutus workload only, Self Adoption on the forger exhibits a very slight uptick (by 3ms).\\n4. In summary, a block producer is able to announce a new header 20ms or 21% earlier into the slot (22ms or 43% under Plutus workload).\\n\\nThe metric _\'Slot start to announced\'_ (see in attachments) is cumulative, and demonstrates how far into a slot the block producing node first announces the new header.\\n\\n### Peer propagation\\n\\n1. Under saturation workload only, Block Fetch duration increases by 14ms (or 4%).\\n2. Under saturation, block adoption is slightly _faster_ (by 3ms), while under Plutus workload it\'s slightly _slower_ (by 2ms).\\n\\n### End-to-end propagation\\n\\nThis metric encompasses block diffusion and adoption across specific percentages of the benchmarking cluster, with 0.80 adoption meaning adoption on 80% of all cluster nodes.  \\n\\n1. Under saturation workload, cluster adoption times on `10.5.0` are identical to those on `10.4.1`.\\n2. Under Plutus workload, they show a moderate 3% - 5% _improvement_, with 7% in the 50th percentile.\\n\\n### Conclusion\\n\\n1. We could not detect any regressions or performance risks to the network on `10.5.0`.\\n2. CPU usage is clearly reduced.\\n3. The forging loop executes faster, new header announcements happen earlier.\\n4. Diffusion / adoption metrics exhibit a small overall improvement and indicate `10.5.0` will deliver network performance at least comparable to `10.4.1`.\\n5. All improvements listed above hinge on the [ledger metrics] feature and will materialize only when using the [new tracing system]. Using the legacy system, `10.5.0` performance is expected to be almost identical to `10.4.1`.\\n\\n## Attachments\\n\\nFull comparison for _value-only workload_, PDF downloadable [here](../static/pdf/benchmarking/release-10.5.0.value-only.pdf).\\n\\nFull comparison for _Plutus workload_, PDF downloadable [here](../static/pdf/benchmarking/release-10.5.0.plutus.pdf).  \\n\\nNB. The benchmarks for `10.5.0` extend to a potential `10.5.1` tag, as that won\'t include any changes with a performance impact; thus, measurements performed on `10.5.0` remain valid.\\n\\n\\n[new tracing system]: https://developers.cardano.org/docs/get-started/cardano-node/new-tracing-system/new-tracing-system\\n[ledger metrics]: https://github.com/IntersectMBO/cardano-node/pull/6180"},{"id":"2025-05-performance-10.4.1","metadata":{"permalink":"/reports/2025-05-performance-10.4.1","editUrl":"https://github.com/intersectmbo/cardano-updates/tree/main/reports/2025-05-performance-10.4.1.md","source":"@site/reports/2025-05-performance-10.4.1.md","title":"Benchmarking -- Node 10.4.1","description":"Setup","date":"2025-05-05T15:29:39.000Z","formattedDate":"May 5, 2025","tags":[{"label":"benchmarking-reports","permalink":"/reports/tags/benchmarking-reports"}],"readingTime":3.05,"hasTruncateMarker":false,"authors":[{"name":"Michael Karg","title":"Performance and Tracing Team Lead","url":"https://github.com/mgmeier","imageURL":"https://github.com/mgmeier.png","key":"mgmeier"}],"frontMatter":{"title":"Benchmarking -- Node 10.4.1","slug":"2025-05-performance-10.4.1","authors":"mgmeier","tags":["benchmarking-reports"],"hide_table_of_contents":false},"prevItem":{"title":"Benchmarking -- Node 10.5.0","permalink":"/reports/2025-07-performance-10.5.0"},"nextItem":{"title":"Benchmarking -- Node 10.3.1","permalink":"/reports/2025-04-performance-10.3.1"}},"content":"## Setup\\n\\nAs part of the release benchmarking cycle, we\'re comparing benchmarking runs for 2 different versions of `cardano-node`:\\n* `10.3.1` - baseline from the previous Node release\\n* `10.4.1` - the current release\\n\\nFor this benchmark, we\'re gathering various metrics under 2 different workloads:\\n1. _value-only_: Each transaction consumes 2 inputs and creates 2 outputs, changing the UTxO set. This workload produces full blocks (> 80kB) exclusively.\\n2. _Plutus_: Each transaction contains a Plutus script exhausting the per-tx execution budget. This workload produces small blocks (< 3kB) exclusively.\\n\\nBenchmarking is performed on a cluster of 52 block producing nodes spread across 3 different AWS regions, interconnected using a static, restricted topology. All runs\\nwere performed in the Conway era.  \\n\\n`10.4.1` features the UTxO-HD in-memory backing store `V2InMemory` of `LedgerDB`, which replaces the in-memory representation of UTxO entries in `10.3` and prior.\\n\\n## Observations\\n\\nThese benchmarks are about evaluating specific corner cases in a constrained environment that allows for reliable reproduction of results; they\'re not trying to directly recreate the operational conditions on Mainnet.  \\n\\n### Resource Usage\\n\\n1. On `10.4.0` under value workload, Heap size increases slightly by 2%, and 5% under Plutus workload. This corresponds to using ~170MiB-390MiB additional RAM.\\n2. Allocation rate and GC impact are virtually unchanged.\\n3. Process CPU usage improves slightly by 2% regardless of workload type.\\n4. CPU 85% spans are slightly (~0.37 slots) _longer_ under value workload, and slightly _shorter_ (~0.33) under Plutus workload.\\n\\nCaveat: Individual metrics can\'t be evaluated in isolate; the resource usage profile as a whole provides insight into the system\'s performance and responsiveness.\\n\\n### Forging Loop\\n\\n1. We can observe a clear improvement in Mempool snapshotting by 9ms or 16% (2ms or 8% under Plutus workload).\\n2. Self-Adoption time improves by 4ms or 5% (and remains virtually unchanged under Plutus workload).\\n3. Hence a block producer is able to announce a new header 10ms or 9% earlier into the slot (1ms or 2% under Plutus workload).\\n\\nThe metric _\'Slot start to announced\'_ (see in attachments) is cumulative, and demonstrates how far into a slot the block producing node first announces the new header.\\n\\n### Peer propagation\\n\\n1. Under value workload, Fetch duration and Fetched to Sending improve slightly by 3ms (1%) and 2ms (4%).\\n2. Under Plutus workload, Fetched to Sending has a slightly longer delay - 2ms (or 5%).\\n\\n### End-to-end propagation\\n\\nThis metric encompasses block diffusion and adoption across specific percentages of the benchmarking cluster, with 0.80 adoption meaning adoption on 80% of all cluster nodes.  \\n\\n1. Under value workload, cluster adoption times exhibit a small 1% - 3% _improvement_ across all percentiles.\\n2. Under Plutus workload, they show a small 1% - 2% _increase_ across all percentiles (except the 80th).\\n\\n### Conclusion\\n\\n1. We could not detect any regressions or performance risks to the network on `10.4.1`.\\n2. There is a small and reasonable price to pay in RAM usage for adding the `LedgerDB` abstraction and thus enable exchangeable backing store implementations.\\n3. On the other hand, CPU usage is reduced slightly by use of the in-memory backing store.\\n4. `10.4.1` is beneficial in all cases for block production metrics; specifically, block producers will be able to announce new headers earlier into the slot.\\n5. Network diffusion and adoption metrics vary only slightly and indicate `10.4.1` will deliver network performance comparable to `10.3.1`.\\n\\n## Attachments\\n\\nFull comparison for _value-only workload_, PDF downloadable [here](../static/pdf/benchmarking/release-10.4.1.value-only.pdf).\\n\\nFull comparison for _Plutus workload_, PDF downloadable [here](../static/pdf/benchmarking/release-10.4.1.plutus.pdf).  \\n\\nNB. The benchmarks for `10.4.1` were performed on tag `10.4.0`. The patch version bump did not include changes relevant to performance; thus, measurements performed on `10.4.0` remain valid. The same holds for `10.3.1` and `10.3.0`."},{"id":"2025-04-performance-10.3.1","metadata":{"permalink":"/reports/2025-04-performance-10.3.1","editUrl":"https://github.com/intersectmbo/cardano-updates/tree/main/reports/2025-04-performance-10.3.1.md","source":"@site/reports/2025-04-performance-10.3.1.md","title":"Benchmarking -- Node 10.3.1","description":"Setup","date":"2025-04-22T13:54:50.000Z","formattedDate":"April 22, 2025","tags":[{"label":"benchmarking-reports","permalink":"/reports/tags/benchmarking-reports"}],"readingTime":4.14,"hasTruncateMarker":false,"authors":[{"name":"Michael Karg","title":"Performance and Tracing Team Lead","url":"https://github.com/mgmeier","imageURL":"https://github.com/mgmeier.png","key":"mgmeier"}],"frontMatter":{"title":"Benchmarking -- Node 10.3.1","slug":"2025-04-performance-10.3.1","authors":"mgmeier","tags":["benchmarking-reports"],"hide_table_of_contents":false},"prevItem":{"title":"Benchmarking -- Node 10.4.1","permalink":"/reports/2025-05-performance-10.4.1"},"nextItem":{"title":"Memory Budget Scaling -- 10.2","permalink":"/reports/2025-03-execbudget-memory-10.2"}},"content":"## Setup\\n\\nAs part of the release benchmarking cycle, we\'re comparing benchmarking runs for 3 different versions of `cardano-node`:\\n* `10.2` - baseline from the previous release (bulit with GHC8.10.7)\\n* `10.3.0-ghc8107` - the current release built with GHC8.10.7\\n* `10.3.0-ghc965` - the current release built with GHC9.6.5\\n\\nFor this benchmark, we\'re gathering various metrics under 2 different workloads:\\n1. _value-only_: Each transaction consumes 2 inputs and creates 2 outputs, changing the UTxO set. This workload produces full blocks (> 80kB) exclusively.\\n2. _Plutus_: Each transaction contains a Plutus script exhausting the per-tx execution budget. This workload produces small blocks (< 3kB) exclusively.\\n\\nBenchmarking is performed on a cluster of 52 block producing nodes spread across 3 different AWS regions, interconnected using a static, restricted topology. All runs\\nwere performed in the Conway era.  \\n\\n`10.3.1` supports two compiler versions, which will be taken into account when comparing performance of different builds of that release.\\n\\n## Observations\\n\\nThese benchmarks are about evaluating specific corner cases in a constrained environment that allows for reliable reproduction of results; they\'re not trying to directly recreate the operational conditions on Mainnet.  \\n\\n### Resource Usage\\n\\n1. `10.3.1` exhibits a clear reduction in Process CPU usage, more prominent under _value workload_:\\n    * value workload: 10% with GHC8, and 24% with GHC9.\\n    * Plutus workload: 4% GHC8, and 6% with GHC9.\\n2. There also is a reduction in RAM usage, more prominent under _Plutus workload_:\\n    * value workload: 1% or ~54MiB with GHC8, and 6% or ~574MiB with GHC9.\\n    * Plutus workload: 14% or ~1.2GiB with GHC9 only.\\n3. Minor GCs and Allocation rate both drop on `10.3.1`, more significantly under _value workload_:\\n    * value workload: 11% each with GHC8, and 24% each with GHC9.\\n    * Plutus workload: 3% and 1% with GHC8; 5% and 4% with GHC9. \\n4. Under value workload, CPU 85% spans _increase_ by 45% with GHC8, but only by 14% with GHC9.\\n5. Under Plutus workload, those spans _decrease_ by 5% with GHC8; even by 19% with GHC9.\\n\\nCaveat: Individual metrics can\'t be evaluated in isolate; the resource usage profile as a whole provides insight into the system\'s performance and responsiveness.\\n\\n### Forging Loop\\n\\n1. Under value workload, several block production metrics improve clearly on `10.3.1`, most prominently Mempool Snapshotting.\\n2. With GHC8, the improvement is 23%, with further significant improvements in Adoption time (11%) and Ledger ticking (10%).\\n3. With GHC9, the improvement is 27%, with further significant improvements in Adoption time (10%) and Ledger ticking (17%).\\n4. Under value workload, this enables a block producer to announce a header earlier into the slot, namely by 23ms (GHC8) and by 28ms (GHC9).\\n5. Under Plutus workload, Adoption time _increases_ by 3ms (6%) with GHC8, but _decreases_ by 8ms (15%) with GHC9.\\n6. Furthermore, there are no significant changes to the header announcement timing.\\n\\nThe metric _\'Slot start to announced\'_ (see in attachments) is cumulative, and demonstrates how far into a slot the block producing node first announces the new header.\\n\\n### Peer propagation\\n\\n1. Under value-only workload only, we observe an increase in Block Fetch duration: 7ms (2%) with GHC8, and 23ms (7%) with GHC9.\\n2. Block adoption times on the peers improve clearly: 11ms (12%) with GHC8, and 12ms (14%) with GHC9.\\n3. Under Plutus workload, however, similarly to the block producer, adoption times _increase_ by 3ms (6%) with GHC8, but _decrease_ by 7ms (13%) with GHC9.\\n\\n### End-to-end propagation\\n\\nThis metric encompasses block diffusion and adoption across specific percentages of the benchmarking cluster, with 0.80 adoption meaning adoption on 80% of all cluster nodes.  \\n\\n1. Under value workload, cluster adoption times on `10.3.1` are largely unchanged.\\n2. With GHC8, there are 5% and 3% improvements in the 50th and 100th centiles; with GHC9, there\'s a small 3% improvement in the 50th centile.\\n3. Under Plutus workload, with GHC8, there\'s a moderate 6% _increase_ in cluster adoption times in the 100th centile.\\n4. With GHC9, however, there\'s a small 2% _improvement_ in all but the 100th centile.\\n\\n### Conclusion\\n\\n1. For `10.3.1` we could not detect any performance risks or regressions.\\n2. Improving resource usage was a stated goal for the `10.3` release; this could be confirmed via measurements for CPU and RAM usage as well as CPU spikes.\\n3. `10.3.1` achieves network performance comparable to `10.2.1` using clearly less system resources - for both compiler versions.\\n4. Several key metrics improve on `10.3.1`: Block producers announce a new header sooner into the slot; we observe lower adoption times (GHC9 only).\\n5. The GHC9.6.5 build has demonstrable performance advantages over the GHC8.10.7 build; especially the Plutus interpreter seems to gain considerably from using GHC9. For those reasons we now recommend *GHC9.6.x* for production builds.\\n\\n\\n## Attachments\\n\\nFull report for _value-only workload_, PDF downloadable [here](../static/pdf/benchmarking/release-10.3.1.value-only.pdf).\\n\\nFull report for _Plutus workload_, PDF downloadable [here](../static/pdf/benchmarking/release-10.3.1.plutus.pdf).  \\n\\nNB. The benchmarks for `10.3.1` were performed on tag `10.3.0`. The patch version bump did not include changes relevant to performance; thus, measurements performed on `10.3.0` remain valid."},{"id":"2025-03-execbudget-memory-10.2","metadata":{"permalink":"/reports/2025-03-execbudget-memory-10.2","editUrl":"https://github.com/intersectmbo/cardano-updates/tree/main/reports/2025-03-execbudget-memory-10.2.md","source":"@site/reports/2025-03-execbudget-memory-10.2.md","title":"Memory Budget Scaling -- 10.2","description":"Setup","date":"2025-04-01T09:50:10.000Z","formattedDate":"April 1, 2025","tags":[{"label":"benchmarking-reports","permalink":"/reports/tags/benchmarking-reports"}],"readingTime":2.645,"hasTruncateMarker":false,"authors":[{"name":"Michael Karg","title":"Performance and Tracing Team Lead","url":"https://github.com/mgmeier","imageURL":"https://github.com/mgmeier.png","key":"mgmeier"}],"frontMatter":{"title":"Memory Budget Scaling -- 10.2","slug":"2025-03-execbudget-memory-10.2","authors":"mgmeier","tags":["benchmarking-reports"],"hide_table_of_contents":false},"prevItem":{"title":"Benchmarking -- Node 10.3.1","permalink":"/reports/2025-04-performance-10.3.1"},"nextItem":{"title":"Memory Budget Scaling -- 10.3","permalink":"/reports/2025-05-execbudget-memory-10.3"}},"content":"## Setup\\n\\nThis report compares benchmarking runs for 3 different settings of the Plutus memory execution budget:\\n* `loop-memx1` - current mainnet memory execution budget\\n* `loop-memx1.5` - 1.5 x current mainnet memory execution budget\\n* `loop-memx2` - 2 x current mainnet memory execution budget\\n\\nFor this comparison, we gather various metrics under the _Plutus_ workload used in release benchmarks: Each block produced during the benchmark contains\\n4 identical script transactions calibrated to fully exhaust the memory execution budget. Thus, script execution is constrained by the memory budget limit\\nevery case. The workload produces small blocks (< 3kB) exclusively.  \\n\\nBenchmarking is performed on a cluster of 52 block producing nodes spread across 3 different AWS regions, interconnected using a static, restricted topology. Node\\nversion 10.2 was used, built with GHC8.10.7.\\n\\n## Observations\\n\\n### Resource Usage\\n\\n1. Scaling the memory budget impacts Allocation Rate and Minor GCs. 1.5 x the budget results in rises of 5% and 6% respecetively; for doubling the budget the corresponding rises are 10% and 11%.\\n2. Those increases seem to correlate linearly with raising mem budget.\\n3. The effect on CPU usage is almost negligible: a 1% (or 3%, for doubling the budget) increase of Process CPU.\\n4. The Node process RAM footprint is unaffected.\\n\\nCaveat: Individual metrics can\'t be evaluated in isolate; the resource usage profile as a whole provides insight into the system\'s performance and responsiveness.\\n\\n### Forging Loop\\n\\n1. Scaling the memory budget has significant impact on block adoption time only.\\n2. Scaling by factor 1.5 leads to a 14ms (or 25%) increase, whereas factor 2 leads to 28ms (49%).\\n\\n### Peer propagation\\n\\n1. Same as on the block producer, scaling the memory budget has significant impact on block adoption times only.\\n2. Scaling by factor 1.5 leads to a 15ms (or 26%) increase, whereas factor 2 leads to 28ms (48%).\\n   \\n### End-to-end propagation\\n\\nThis metric encompasses block diffusion and adoption across specific percentages of the benchmarking cluster, with 0.80 adoption meaning adoption on 80% of all cluster nodes.  \\n\\n1. 1.5 x the memory budget results in a slight increase of 19ms - 22ms in cluster adoption times (4% - 5%).\\n2. 2 x the memory budget results in a moderate 27ms - 34ms increase (5% - 7%, with 9% in the 50th centile).\\n\\n### Conclusion\\n\\nThese measurements outline the headroom for raising the memory budget, along with the expected performance impact:\\n1. Block adoption time is the only metric that\'s affected significantly, increasing both on the forger and the peers by the same extent.\\n2. These increases seem to correspond linearly with the raising the memory budget. This gives excellent predictability of performance impact.\\n3. Expectedly, more allocations happen; we can observe the same linear correspondence here as well.\\n4. It has to be pointed out that block diffusion is only slightly affected by changing the execution budget: Due to pipelining, announcing and (re-)sending a block precedes adoption in most cases.\\n5. As such, regarding absolute cluster adoption times, measurements taken with either budget adjustment do not exhibit performance risks to the network. They do illustrate, however, the performance cost of those budget adjustments.\\n\\n## Attachment\\n\\nFull report PDF downloadable [here](../static/pdf/benchmarking/execbudget-10.2-mem_scaling.pdf)."},{"id":"2025-05-execbudget-memory-10.3","metadata":{"permalink":"/reports/2025-05-execbudget-memory-10.3","editUrl":"https://github.com/intersectmbo/cardano-updates/tree/main/reports/2025-05-execbudget-memory-10.3.md","source":"@site/reports/2025-05-execbudget-memory-10.3.md","title":"Memory Budget Scaling -- 10.3","description":"Setup","date":"2025-04-01T09:50:10.000Z","formattedDate":"April 1, 2025","tags":[{"label":"benchmarking-reports","permalink":"/reports/tags/benchmarking-reports"}],"readingTime":3.58,"hasTruncateMarker":false,"authors":[{"name":"Michael Karg","title":"Performance and Tracing Team Lead","url":"https://github.com/mgmeier","imageURL":"https://github.com/mgmeier.png","key":"mgmeier"}],"frontMatter":{"title":"Memory Budget Scaling -- 10.3","slug":"2025-05-execbudget-memory-10.3","authors":"mgmeier","tags":["benchmarking-reports"],"hide_table_of_contents":false},"prevItem":{"title":"Memory Budget Scaling -- 10.2","permalink":"/reports/2025-03-execbudget-memory-10.2"},"nextItem":{"title":"Benchmarking -- UTxO-HD on 10.2","permalink":"/reports/2025-02-performance-utxohd-10.2"}},"content":"## Setup\\n\\nThis report compares benchmarking runs for 3 different settings of the Plutus memory execution budget:\\n* `10.3-ghc965` - current mainnet memory execution budget\\n* `loop-memx1.5` - 1.5 x current mainnet memory execution budget\\n* `loop-memx2` - 2 x current mainnet memory execution budget\\n\\nFor this comparison, we gather various metrics under the _Plutus_ workload used in release benchmarks: Each block produced during the benchmark contains\\n4 identical script transactions calibrated to fully exhaust the memory execution budget. Thus, script execution is constrained by the memory budget limit\\nevery case. The workload produces small blocks (< 3kB) exclusively. \\n\\nBenchmarking is performed on a cluster of 52 block producing nodes spread across 3 different AWS regions, interconnected using a static, restricted topology. Node\\nversion 10.3 was used, built with GHC9.6.5. This is a re-run of the scaling benchmarks performed on Node version 10.2 / GHC8.10 to document impact of performance improvements. Those results\\nwere published here on [Cardano Updates].\\n\\n## Observations\\n\\n### Resource Usage\\n\\n1. Scaling the memory budget impacts Allocation Rate and Minor GCs. 1.5 x the budget results in rises of 5% each; for doubling the budget the corresponding rises are 8% and 9%.\\n2. Those increases seem to correlate linearly with raising mem budget.\\n3. The effects on CPU usage and RAM footprint are negligible for both scaling factors.\\n\\nCaveat: Individual metrics can\'t be evaluated in isolate; the resource usage profile as a whole provides insight into the system\'s performance and responsiveness.\\n\\n### Forging Loop\\n\\n1. Scaling the memory budget has significant impact on block adoption time only.\\n2. Scaling by factor 1.5 leads to a 10ms (or 24%) increase, whereas factor 2 leads to 21ms (50%).\\n\\n### Peer propagation\\n\\n1. Same as on the block producer, scaling the memory budget has significant impact on block adoption times only.\\n2. Scaling by factor 1.5 leads to a 11ms (or 24%) increase, whereas factor 2 leads to 19ms (42%).\\n   \\n### End-to-end propagation\\n\\nThis metric encompasses block diffusion and adoption across specific percentages of the benchmarking cluster, with 0.80 adoption meaning adoption on 80% of all cluster nodes.  \\n\\n1. 1.5 x the memory budget results in a slight increase of  9ms - 31ms in cluster adoption times (3% - 6%).\\n2. 2 x the memory budget results in a moderate 17ms - 35ms increase (5% - 7%).\\n\\n### Conclusion\\n\\nThese measurements outline the headroom for raising the memory budget, along with the expected performance impact:\\n1. Block adoption time is the only metric that\'s affected significantly, increasing both on the forger and the peers by the same extent.\\n2. These increases seem to correspond linearly with the raising the memory budget. This gives excellent predictability of performance impact.\\n3. Expectedly, more allocations happen; we can observe the same linear correspondence here as well.\\n4. It has to be pointed out that block diffusion is only slightly affected by changing the execution budget: Due to pipelining, announcing and (re-)sending a block precedes adoption in most cases.\\n5. As such, regarding absolute cluster adoption times, measurements taken with either budget adjustment do not exhibit performance risks to the network. They do illustrate, however, the performance cost of those budget adjustments.\\n\\nThese scaling benchmarks are complementary to those performed on Node 10.2; in comparison with those, we can additionally conclude:\\n1. The conclusions from measurements for each scaling run set are identical.\\n2. While the relative increases in adoption time for both Node builds are quite similar, the absolute increases are 22% - 32% _smaller_ (i.e., adoption happens more efficiently) for 10.3 / GHC9.6.\\n3. The same rationale applies to end-to-end propagation metrics: Absolute values document faster cluster adoption for 10.3 / GHC9.6. \\n4. Incidentally, the absolute values for scaling factor 1 on 10.2 are close to those for scaling factor 2 on 10.3 except for the tail end (i.e. 95th percentile and above).\\n5. This reflects the performance improvements that were a stated goal for the 10.3 release - and suggests the performance cost of memory budget increases has become slightly _smaller_ in absolute terms.\\n\\nAs adoption times are not only impacted by Plutus execution alone, we still advocate for a conservative and/or multi-stage raise; future backpedaling on budget limits could cause issues for scripts already deployed.\\n\\n## Attachment\\n\\nFull report PDF downloadable [here](../static/pdf/benchmarking/execbudget-10.3-mem_scaling.pdf).\\n\\n[Cardano Updates]: https://updates.cardano.intersectmbo.org/reports/2025-03-execbudget-memory-10.2"},{"id":"2025-02-performance-utxohd-10.2","metadata":{"permalink":"/reports/2025-02-performance-utxohd-10.2","editUrl":"https://github.com/intersectmbo/cardano-updates/tree/main/reports/2025-02-performance-utxohd-10.2.md","source":"@site/reports/2025-02-performance-utxohd-10.2.md","title":"Benchmarking -- UTxO-HD on 10.2","description":"Setup","date":"2025-02-21T17:25:57.000Z","formattedDate":"February 21, 2025","tags":[{"label":"benchmarking-reports","permalink":"/reports/tags/benchmarking-reports"}],"readingTime":2.305,"hasTruncateMarker":false,"authors":[{"name":"Michael Karg","title":"Performance and Tracing Team Lead","url":"https://github.com/mgmeier","imageURL":"https://github.com/mgmeier.png","key":"mgmeier"}],"frontMatter":{"title":"Benchmarking -- UTxO-HD on 10.2","slug":"2025-02-performance-utxohd-10.2","authors":"mgmeier","tags":["benchmarking-reports"],"hide_table_of_contents":false},"prevItem":{"title":"Memory Budget Scaling -- 10.3","permalink":"/reports/2025-05-execbudget-memory-10.3"},"nextItem":{"title":"Benchmarking -- Node 10.2.1","permalink":"/reports/2025-02-performance-10.2.1"}},"content":"## Setup\\n\\nThis report compares benchmarking runs for 2 different flavours of `cardano-node`:\\n* `10.2-regular` - regular Node performance baseline from the `10.2.x` release benchmarks.\\n* `10.2-utxohd` - the UTxO-HD build of the Node based on that same version.\\n\\nFor this benchmark, we\'re gathering various metrics under the _value-only_ workload used in release benchmarks: Each transaction consumes 2 inputs and creates 2 outputs, \\nchanging the UTxO set. This workload produces full blocks (> 80kB) exclusively. Moreover, it\'s the workload that produces most stress on the UTxO set. Thus, it\'s the most meaningful\\nworkload when it comes to benchmarking UTxO-HD.  \\n\\nWe target the _in-memory backing store_ of UTxO-HD - LedgerDB V2 in this case. The on-disk backend is not used. \\n\\nBenchmarking is performed on a cluster of 52 block producing nodes spread across 3 different AWS regions, interconnected using a static, restricted topology.\\n\\n## Observations\\n\\n### Resource Usage\\n\\n1. With UTxO-HD\'s in-memory backend, the memory footprint increases slightly by 3%.\\n2. Process CPU usage is moderately reduced by 9% with UTxO-HD.\\n3. Additionally, CPU 85% spans decrease in duration by 24% (~1.1 slots).\\n\\nCaveat: Individual metrics can\'t be evaluated in isolate; the resource usage profile as a whole provides insight into the system\'s performance and responsiveness.\\n\\n### Forging Loop\\n\\n1. Block context acquisition improves by 3ms (or 11%), while Ledger ticking takes 3ms (or 10%) longer.\\n2. Creating a mempool snapshot is significantly faster - by 16ms (or 21%).\\n3. As a result, a UTxO-HD block producing node is able to announce a new header 17ms (or 12%) earlier into a slot.\\n4. Additionally, adoption time on the forger is slightly improved - by 4ms (or 5%).\\n\\n### Peer propagation\\n\\n1. Block fetch duration increases moderately by 13ms or 4%.\\n2. Adoption times on the peers improve very slightly - by 2ms or 2%.\\n\\n### End-to-end propagation\\n\\nThis metric encompasses block diffusion and adoption across specific percentages of the benchmarking cluster, with 0.80 adoption meaning adoption on 80% of all cluster nodes.  \\n\\n1. There is no significant difference in cluster adoption times between regular and UTxO-HD node.\\n\\n### Conclusion\\n\\nRegarding the UTxO-HD build using the in-memory LedgerDB V2 backend, we can conclude that:\\n1. it is lighter on CPU usage compared to the regular node, albeit requiring just slightly more RAM.\\n2. it poses no performance risk to block producers; on the contrary, the changes in forging loop metrics seem favourable compared to the regular node.  \\n3. network performance would be expeceted to be on par with the regular node.\\n4. even under stress, there is no measurable performance regression compared to the regular node.\\n5. as a consequence of the above, performance-wise, it\'s a viable replacement for the regular in-memory solution.\\n\\n## Attachment\\n\\nFull report for _value-only workload_, PDF downloadable [here](../static/pdf/benchmarking/utxohd-10.2.value-only.pdf)."},{"id":"2025-02-performance-10.2.1","metadata":{"permalink":"/reports/2025-02-performance-10.2.1","editUrl":"https://github.com/intersectmbo/cardano-updates/tree/main/reports/2025-02-performance-10.2.1.md","source":"@site/reports/2025-02-performance-10.2.1.md","title":"Benchmarking -- Node 10.2.1","description":"Setup","date":"2025-02-21T13:39:30.000Z","formattedDate":"February 21, 2025","tags":[{"label":"benchmarking-reports","permalink":"/reports/tags/benchmarking-reports"}],"readingTime":2.67,"hasTruncateMarker":false,"authors":[{"name":"Michael Karg","title":"Performance and Tracing Team Lead","url":"https://github.com/mgmeier","imageURL":"https://github.com/mgmeier.png","key":"mgmeier"}],"frontMatter":{"title":"Benchmarking -- Node 10.2.1","slug":"2025-02-performance-10.2.1","authors":"mgmeier","tags":["benchmarking-reports"],"hide_table_of_contents":false},"prevItem":{"title":"Benchmarking -- UTxO-HD on 10.2","permalink":"/reports/2025-02-performance-utxohd-10.2"},"nextItem":{"title":"Benchmarking -- Node 10.1.4","permalink":"/reports/2025-01-performance-10.1.4"}},"content":"## Setup\\n\\nAs part of the release benchmarking cycle, we\'re comparing benchmarking runs for 2 different versions of `cardano-node`:\\n* `10.1.4` - baseline from a previous mainnet release\\n* `10.2.1` - the current release\\n\\nFor this benchmark, we\'re gathering various metrics under 2 different workloads:\\n1. _value-only_: Each transaction consumes 2 inputs and creates 2 outputs, changing the UTxO set. This workload produces full blocks (> 80kB) exclusively.\\n2. _Plutus_: Each transaction contains a Plutus script exhausting the per-tx execution budget. This workload produces small blocks (< 3kB) exclusively.\\n\\nBenchmarking is performed on a cluster of 52 block producing nodes spread across 3 different AWS regions, interconnected using a static, restricted topology. All runs\\nwere performed in the Conway era.\\n\\n## Observations\\n\\nThese benchmarks are about evaluating specific corner cases in a constrained environment that allows for reliable reproduction of results; they\'re not trying to directly recreate the operational conditions on Mainnet.  \\n\\n### Resource Usage\\n\\n1. CPU usage increases moderately by 12% under value, and very slightly by 2% under Plutus workload.\\n2. CPU 85% spans increase by 14% (~0.6 slots) under value workload, but decrease by 6% (~0.8 slots) under Plutus workload.\\n3. Only under value workload, we observe a slight increase in Allocation rate and Minor GCs of 9% and 8%\\n\\nCaveat: Individual metrics can\'t be evaluated in isolate; the resource usage profile as a whole provides insight into the system\'s performance and responsiveness.\\n\\n### Forging Loop\\n\\n1. Adoption time on the forger improves by 3ms (or 4%) - and 5ms (or 9%) under Plutus workload.\\n2. Block context acquisition takes 3ms (or 12%) longer under value workload.\\n3. Under Plutus workload only, ledger ticking improves by 3ms (or 12%).\\n\\nThe metric _\'Slot start to announced\'_ (see in attachments) is cumulative, and demonstrates how far into a slot the block producing node first announces the new header.\\n\\n### Peer propagation\\n\\n1. Block fetch duration improves clearly by 16ms (or 4%) under value-only workload.\\n2. Under Plutus workload, we can measure an improvement by 4ms (or 7%) for adoption times on the peers.\\n\\n### End-to-end propagation\\n\\nThis metric encompasses block diffusion and adoption across specific percentages of the benchmarking cluster, with 0.80 adoption meaning adoption on 80% of all cluster nodes.  \\n\\nAs a result of the above, on `10.2.1` exhibits:\\n1. a slight 3% improvement in cluster adoption times in the 80th centile and above under value workload.\\n2. a near-jitter 1% - 3% improvement in cluster adoption times under Plutus workload.\\n\\n### Conclusion\\n\\n1. We could not detect any significant regressions, or performance risks, on `10.2.1`.\\n2. `10.2.1` comes with slightly increased CPU usage, and no changes to RAM footprint.\\n3. Diffusion metrics very slightly improve - mainly due to block fetch being more efficient for full blocks, and adoption for blocks exclusively containing Plutus transactions.\\n4. This points to network performance of `10.2.1` being on par with or very slightly better than `10.1.4`.\\n\\n## Attachments\\n\\nFull report for _value-only workload_, PDF downloadable [here](../static/pdf/benchmarking/release-10.2.1.value-only.pdf).\\n\\nFull report for _Plutus workload_, PDF downloadable [here](../static/pdf/benchmarking/release-10.2.1.plutus.pdf).  \\n\\nNB. The benchmarks for `10.2.1` were performed on tag `10.2.0`. The patch version bump did not include changes relevant to performance; thus, measurements and observations performed on `10.2.0` remain valid."},{"id":"2025-01-performance-10.1.4","metadata":{"permalink":"/reports/2025-01-performance-10.1.4","editUrl":"https://github.com/intersectmbo/cardano-updates/tree/main/reports/2025-01-performance-10.1.4.md","source":"@site/reports/2025-01-performance-10.1.4.md","title":"Benchmarking -- Node 10.1.4","description":"Setup","date":"2025-01-10T12:16:13.000Z","formattedDate":"January 10, 2025","tags":[{"label":"benchmarking-reports","permalink":"/reports/tags/benchmarking-reports"}],"readingTime":2.605,"hasTruncateMarker":false,"authors":[{"name":"Michael Karg","title":"Performance and Tracing Team Lead","url":"https://github.com/mgmeier","imageURL":"https://github.com/mgmeier.png","key":"mgmeier"}],"frontMatter":{"title":"Benchmarking -- Node 10.1.4","slug":"2025-01-performance-10.1.4","authors":"mgmeier","tags":["benchmarking-reports"],"hide_table_of_contents":false},"prevItem":{"title":"Benchmarking -- Node 10.2.1","permalink":"/reports/2025-02-performance-10.2.1"},"nextItem":{"title":"Benchmarking -- Node 10.1.1","permalink":"/reports/2024-10-performance-10.1.1"}},"content":"## Setup\\n\\nAs part of the release benchmarking cycle, we\'re comparing benchmarking runs for 2 different versions of `cardano-node`:\\n* `10.1.1` - baseline from a previous mainnet release\\n* `10.1.4` - the current mainnet release\\n\\nFor this benchmark, we\'re gathering various metrics under 2 different workloads:\\n1. _value-only_: Each transaction consumes 2 inputs and creates 2 outputs, changing the UTxO set. This workload produces full blocks (> 80kB) exclusively.\\n2. _Plutus_: Each transaction contains a Plutus script exhausting the per-tx execution budget. This workload produces small blocks (< 3kB) exclusively.\\n\\nBenchmarking is performed on a cluster of 52 block producing nodes spread across 3 different AWS regions, interconnected using a static, restricted topology. All runs\\nwere performed in the Conway era.\\n\\n## Observations\\n\\nThese benchmarks are about evaluating specific corner cases in a constrained environment that allows for reliable reproduction of results; they\'re not trying to directly recreate the operational conditions on Mainnet.  \\n\\n### Resource Usage\\n\\n1. CPU 85% spans slightly increase by 6% or ~0.2 slots (26% or ~2.9 slots under Plutus workload).\\n2. We can observe a tiny increase in memory usage by 1-2% (132-160 MiB).\\n\\nCaveat: Individual metrics can\'t be evaluated in isolate; the resource usage profile as a whole provides insight into the system\'s performance and responsiveness.\\n\\n### Forging Loop\\n\\n1. Under value workload, Ledger Ticking and Self Adoption exhibit a very slight increase (2ms each).\\n2. Block Context Acquisition has improved by 2ms.\\n3. Under Plutus workload, there are no significant changes to forger metrics.\\n\\nThe metric _\'Slot start to announced\'_ (see in attachments) is cumulative, and demonstrates how far into a slot the block producing node first announces the new header.\\n\\n### Peer propagation\\n\\n1. There\'s a minor increase of 1% (3ms) in Block Fetch duration under value workload only.\\n2. Under Plutus workload, we can measure a small improvement by 2% for adoption times on the peers.\\n\\n### End-to-end propagation\\n\\nThis metric encompasses block diffusion and adoption across specific percentages of the benchmarking cluster, with 0.80 adoption meaning adoption on 80% of all cluster nodes.  \\n\\nAs a result of the above, on `10.1.4` we can observe:\\n1. a tiny increase in cluster adoption times of 1%-2% in the 80th centile and above under value workload.\\n2. an improvement in cluster adoption times of 3%-4% in the tail end (95th centile and above) under Plutus workload.\\n\\n### Conclusion\\n\\n1. For `10.1.4`, we could not detect any regressions or performance risks.\\n2. All increases or decreases in forger and peer metrics are 3ms and less. This indicates network performance of `10.1.4` will very closely match that of `10.1.1` and subsequent patch releases.\\n3. There\'s no significant change in the resource usage pattern. The increased CPU 85% spans tend to barely manifest when the system is under heavy load (value workload); as such, they pose no cause for concern. \\n\\n## Attachments\\n\\nFull report for _value-only workload_, PDF downloadable [here](../static/pdf/benchmarking/release-10.1.4.value-only.pdf).\\n\\nFull report for _Plutus workload_, PDF downloadable [here](../static/pdf/benchmarking/release-10.1.4.plutus.pdf).  \\n\\nNB. The benchmarks for `10.1.1` were performed on tag `10.0.0-pre`. The minor version bump did not include changes relevant to performance; thus, measurements taken on `10.0.0-pre` remain a valid baseline."},{"id":"2024-10-performance-10.1.1","metadata":{"permalink":"/reports/2024-10-performance-10.1.1","editUrl":"https://github.com/intersectmbo/cardano-updates/tree/main/reports/2024-10-performance-10.1.1.md","source":"@site/reports/2024-10-performance-10.1.1.md","title":"Benchmarking -- Node 10.1.1","description":"Setup","date":"2024-10-31T11:03:27.000Z","formattedDate":"October 31, 2024","tags":[{"label":"benchmarking-reports","permalink":"/reports/tags/benchmarking-reports"}],"readingTime":3.925,"hasTruncateMarker":false,"authors":[{"name":"Michael Karg","title":"Performance and Tracing Team Lead","url":"https://github.com/mgmeier","imageURL":"https://github.com/mgmeier.png","key":"mgmeier"}],"frontMatter":{"title":"Benchmarking -- Node 10.1.1","slug":"2024-10-performance-10.1.1","authors":"mgmeier","tags":["benchmarking-reports"],"hide_table_of_contents":false},"prevItem":{"title":"Benchmarking -- Node 10.1.4","permalink":"/reports/2025-01-performance-10.1.4"},"nextItem":{"title":"Benchmarking -- Node 8.9.0","permalink":"/reports/2024-03-performance-8.9.0"}},"content":"## Setup\\n\\nAs part of the release benchmarking cycle, we\'re comparing benchmarking runs for 2 different versions of `cardano-node`:\\n* `9.2.0` - baseline from a previous mainnet release\\n* `10.1.1` - the current mainnet release\\n\\nFor this benchmark, we\'re gathering various metrics under 3 different workloads:\\n1. _value-only_: Each transaction consumes 2 inputs and creates 2 outputs, changing the UTxO set. This workload produces full blocks (> 80kB) exclusively.\\n2. _Plutus_: Each transaction contains a Plutus script exhausting the per-tx execution budget. This workload produces small blocks (< 3kB) exclusively.\\n3. _value+voting_: On top of above value workload, this one has DReps vote on and ratify governance actions - forcing additional computation for vote tallying and proposal enactment.\\n\\nBenchmarking is performed on a cluster of 52 block producing nodes spread across 3 different AWS regions, interconnected using a static, restricted topology. All runs\\nwere performed in the Conway era.\\n\\n## Observations\\n\\nThese benchmarks are about evaluating specific corner cases in a constrained environment that allows for reliable reproduction of results; they\'re not trying to directly recreate the operational conditions on Mainnet.  \\n\\n### Resource Usage\\n\\n1. `10.1.1` shows an improvement of 4% (8% under Plutus workload) in Process CPU usage.\\n2. Allocation Rate improves by 8% (11% under Plutus workload), while Heap Size remains unchanged.\\n3. CPU 85% spans decrease by 18% (5% under Plutus workload).\\n4. Compared to value-only workload, ongoing voting leads to a slight increase of 5% in Process CPU usage.\\n\\nCaveat: Individual metrics can\'t be evaluated in isolate; the resource usage profile as a whole provides insight into the system\'s performance and responsiveness.\\n\\n### Forging Loop\\n\\n1. Under Plutus workload, `10.1.1` exhibits a formidable speedup of 70ms in the forging loop - due to mempool snapshots being produced much more quickly.\\n2. Under value workload, there are no significant changes to forger metrics.\\n3. With voting added on top of the value workload, we can observe mempool snapshots and adoption time on the block producer rise by 10ms each.\\n\\nThe metric _\'Slot start to announced\'_ (see in attachments) is cumulative, and demonstrates how far into a slot the block producing node first announces the new header.\\n\\n### Peer propagation\\n\\n1. Block Fetch duration increases slightly by 16ms (or 5%) under value workload.\\n2. Under Plutus workload, there are no significant changes to peer-related metrics.\\n3. With the additional voting workload, peer adoption times rise by 12ms on average - confirming the observation for adoption time on the block producer.\\n\\n### End-to-end propagation\\n\\nThis metric encompasses block diffusion and adoption across specific percentages of the benchmarking cluster, with 0.80 adoption meaning adoption on 80% of all cluster nodes.  \\n\\n1. `10.1.1` exhibits a slight increase of 2% - 3% in cluster adoption times under value workload.\\n2. Under Plutus workload however, we observe significant improvement of 18% up to the 50th centile, and 9% - 13% in the 80th centile and above.\\n3. While the former is due to slightly increased Block Fetch duration, the latter is the consequence of much quicker mempool snapshots involving Plutus transactions.\\n4. Submitting the additional voting workload, we can observe a consistent 4% - 6% increase in cluster adoption times across all centiles.\\n\\n### Conclusion\\n\\n* We do not detect any perfomance regression in `10.1.1` compared to `9.2.0`.\\n* To the contrary - `10.1.1` is lighter on the Node process resource usage overall.\\n* Improved forging and diffusion timings can be expected for blocks heavy on Plutus transactions.\\n* Stressing the governance / voting capabalities of the Conway ledger lets us ascertain an (expected) performance cost of voting.\\n* This cost has demonstrated to be reasonable, and to not contain lurking perfomance risks to the system.\\n* It is expected to manifest only during periods of heavy vote tallying / proposal enactment, slightly affecting block adoption times.\\n\\nNB. The same amount of DReps are registered for each workload. However, only under _value+voting_ do they become active by submitting votes. This requires an increased UTxO set size, so it uses\\na baseline seperate from _value-only_, resulting in slightly different absolute values.  \\n\\n## Contact\\n\\nAs for publishing such benchmarking results, we are aware that more context and detail may be needed with regard to specfic metrics or benchmarking methodology. \\n\\nWe are still looking to gather questions, both general and specific, so that we can provide a suitable FAQ and possibly improve presentation in the future.\\n\\n## Attachments\\n\\nFull report for _value-only workload_, PDF downloadable [here](../static/pdf/benchmarking/release-10.1.1.value-only.pdf).\\n\\nFull report for _Plutus workload_, PDF downloadable [here](../static/pdf/benchmarking/release-10.1.1.plutus.pdf).  \\n\\nFull report for _value+voting workload_, PDF downloadable [here](../static/pdf/benchmarking/release-10.1.1.voting.pdf).  \\n\\nNB. The release benchmarks for `10.1.1` were performed on tag `10.0.0-pre`. The minor version bump did not include changes relevant to performance; thus, measurements taken on `10.0.0-pre` remain valid."},{"id":"2024-03-performance-8.9.0","metadata":{"permalink":"/reports/2024-03-performance-8.9.0","editUrl":"https://github.com/intersectmbo/cardano-updates/tree/main/reports/2024-03-performance-8.9.0.md","source":"@site/reports/2024-03-performance-8.9.0.md","title":"Benchmarking -- Node 8.9.0","description":"Setup","date":"2024-03-13T09:34:49.000Z","formattedDate":"March 13, 2024","tags":[{"label":"benchmarking-reports","permalink":"/reports/tags/benchmarking-reports"}],"readingTime":2.43,"hasTruncateMarker":false,"authors":[{"name":"Michael Karg","title":"Performance and Tracing Team Lead","url":"https://github.com/mgmeier","imageURL":"https://github.com/mgmeier.png","key":"mgmeier"}],"frontMatter":{"title":"Benchmarking -- Node 8.9.0","slug":"2024-03-performance-8.9.0","authors":"mgmeier","tags":["benchmarking-reports"],"hide_table_of_contents":false},"prevItem":{"title":"Benchmarking -- Node 10.1.1","permalink":"/reports/2024-10-performance-10.1.1"},"nextItem":{"title":"Benchmarking -- Node 8.9.1","permalink":"/reports/2024-03-performance-8.9.1"}},"content":"## Setup\\n\\nAs part of the release benchmarking cycle, we\'re comparing benchmarking runs for 3 different versions of `cardano-node`:\\n* `8.7.2` - baseline for previous mainnet release\\n* `8.8.0` - an intermediate reference point\\n* `8.9.0` - the next mainnet release\\n\\nFor each version, we\'re gathering various metrics under 2 different workloads:\\n1. _value-only_: Each transaction consumes 2 inputs and creates 2 outputs, changing the UTxO set. This workload produces full blocks (> 80kB) exclusively.\\n2. _Plutus_: Each transaction contains a Plutus script exhausting the per-tx execution budget. This workload produces small blocks (< 3kB) exclusively.\\n\\nBenchmarking is performed on a cluster of 52 block producing nodes spread across 3 different AWS regions, interconnected using a static, restricted topology. All runs\\nwere performed in the Babbage era.\\n\\n\\n## Observations\\n\\nThese benchmarks are about evaluating specific corner cases in a constrained environment that allows for reliable reproduction of results; they\'re not trying to directly recreate the operational conditions on Mainnet.  \\n\\nThe observations stated refer to the direct comparison between the `8.7.2` and `8.9.0` versions.\\n\\n### Resource Usage\\n\\n1. Overall CPU usage exhibits a small to moderate (5% - 8%) increase.\\n2. Memory usage is very slightly decreased by 1%.\\n\\nCaveat: Individual metrics can\'t be evaluated in isolate; the resource usage profile as a whole provides insight into the system\'s performance and responsiveness.\\n\\n\\n### Forging Loop\\n\\n1. For full blocks, Mempool Snapshotting improves by 4% (or 3ms).\\n2. For small blocks, Self Adoption times improve by 8% (or 4ms).\\n3. All other forger metrics do not exhibit significant change.\\n\\nThe metric _\'Slot start to announced\'_ (see in attachments) is cumulative, and demonstrates how far into a slot the block producing node first announces the new header.\\n\\n### Peer propagation\\n\\n1. For full blocks, Block Fetch duration shows a notable improvement by 10ms (or 3%).\\n\\n### End-to-end propagation\\n\\nThis metric encompasses block diffusion and adoption across specific percentages of the benchmarking cluster, with 0.80 adoption meaning adoption on 80% of all cluster nodes.  \\n\\nEnd-to-end propagation times on `8.9.0` exhibit a small improvement by 2% across all centiles for full blocks, whereas they remain largely unchanged for small blocks.\\n\\n\\n### Conclusion\\n\\n* The performance changes observed between `8.9.0` and `8.7.2` are only minor - with `8.9.0` slightly improving on `8.7.2`. Therefore, we\'d expect `8.9.0` Mainnet performance to be akin to `8.7.2`.\\n* We have demonstrated no performance regression has been introduced in `8.9.0`.\\n\\n## Contact\\n\\nAs for publishing such benchmarking results, we are aware that more context and detail may be needed with regard to specfic metrics or benchmarking methodology. \\n\\nWe are still looking to gather questions, both general and specific, so that we can provide a suitable FAQ and possibly improve presentation in the future.\\n\\n## Attachments\\n\\nFull report for _value-only workload_, PDF downloadable [here](../static/pdf/benchmarking/release-8.9.0.value-only.pdf).\\n\\nFull report for _Plutus workload_, PDF downloadable [here](../static/pdf/benchmarking/release-8.9.0.plutus.pdf).\\n\\nNB. Mainnet release `8.7.3` did not include any performance-related changes; measurements taken on `8.7.2` remain valid."},{"id":"2024-03-performance-8.9.1","metadata":{"permalink":"/reports/2024-03-performance-8.9.1","editUrl":"https://github.com/intersectmbo/cardano-updates/tree/main/reports/2024-03-performance-8.9.1.md","source":"@site/reports/2024-03-performance-8.9.1.md","title":"Benchmarking -- Node 8.9.1","description":"Setup","date":"2024-03-13T09:34:49.000Z","formattedDate":"March 13, 2024","tags":[{"label":"benchmarking-reports","permalink":"/reports/tags/benchmarking-reports"}],"readingTime":2.285,"hasTruncateMarker":false,"authors":[{"name":"Michael Karg","title":"Performance and Tracing Team Lead","url":"https://github.com/mgmeier","imageURL":"https://github.com/mgmeier.png","key":"mgmeier"}],"frontMatter":{"title":"Benchmarking -- Node 8.9.1","slug":"2024-03-performance-8.9.1","authors":"mgmeier","tags":["benchmarking-reports"],"hide_table_of_contents":false},"prevItem":{"title":"Benchmarking -- Node 8.9.0","permalink":"/reports/2024-03-performance-8.9.0"},"nextItem":{"title":"Benchmarking -- Node 8.9.3","permalink":"/reports/2024-05-performance-8.9.3"}},"content":"## Setup\\n\\nAs part of the release benchmarking cycle, we\'re comparing benchmarking runs for 2 different versions of `cardano-node`:\\n* `8.9.0` - baseline for previous mainnet release\\n* `8.9.1` - the next mainnet release\\n\\nFor each version, we\'re gathering various metrics under 2 different workloads:\\n1. _value-only_: Each transaction consumes 2 inputs and creates 2 outputs, changing the UTxO set. This workload produces full blocks (> 80kB) exclusively.\\n2. _Plutus_: Each transaction contains a Plutus script exhausting the per-tx execution budget. This workload produces small blocks (< 3kB) exclusively.\\n\\nBenchmarking is performed on a cluster of 52 block producing nodes spread across 3 different AWS regions, interconnected using a static, restricted topology. All runs\\nwere performed in the Babbage era.\\n\\n\\n## Observations\\n\\nThese benchmarks are about evaluating specific corner cases in a constrained environment that allows for reliable reproduction of results; they\'re not trying to directly recreate the operational conditions on Mainnet.  \\n\\n### Resource Usage\\n\\n1. We can observe an overall decrease in CPU usage (2% - 4%); only GC CPU usage under value workload increases by 3%.\\n2. Under value workload only, Allocation rate is very slightly decreased (1%) with no change to Heap Size.\\n\\nCaveat: Individual metrics can\'t be evaluated in isolate; the resource usage profile as a whole provides insight into the system\'s performance and responsiveness.\\n\\n\\n### Forging Loop\\n\\n1. Mempool Snapshot duration increases slightly by 2ms under value workload.\\n2. Self-Adoption time increases by 3ms.\\n3. All other forger metrics do not exhibit significant change.\\n\\nThe metric _\'Slot start to announced\'_ (see in attachments) is cumulative, and demonstrates how far into a slot the block producing node first announces the new header.\\n\\n### Peer propagation\\n\\n1. Under value workload only, Block Fetch duration and Fetched to Sending show a slight increase of 2ms each.\\n\\n### End-to-end propagation\\n\\nThis metric encompasses block diffusion and adoption across specific percentages of the benchmarking cluster, with 0.80 adoption meaning adoption on 80% of all cluster nodes.  \\n\\nEnd-to-end propagation times on `8.9.1` exhibit a small increase by 1% - 2% for full blocks, while remaining virtually unchanged for small blocks.\\n\\n\\n### Conclusion\\n\\n* The performance changes measured between `8.9.1` and `8.9.0` are very minor. Mainnnet performance of `8.9.1` is expected to be akin to `8.9.0`.\\n* We have not observed any performance regression being introduced in `8.9.1`.\\n\\n## Contact\\n\\nAs for publishing such benchmarking results, we are aware that more context and detail may be needed with regard to specfic metrics or benchmarking methodology. \\n\\nWe are still looking to gather questions, both general and specific, so that we can provide a suitable FAQ and possibly improve presentation in the future.\\n\\n## Attachments\\n\\nFull report for _value-only workload_, PDF downloadable [here](../static/pdf/benchmarking/release-8.9.1.value-only.pdf).\\n\\nFull report for _Plutus workload_, PDF downloadable [here](../static/pdf/benchmarking/release-8.9.1.plutus.pdf)."},{"id":"2024-05-performance-8.9.3","metadata":{"permalink":"/reports/2024-05-performance-8.9.3","editUrl":"https://github.com/intersectmbo/cardano-updates/tree/main/reports/2024-05-performance-8.9.3.md","source":"@site/reports/2024-05-performance-8.9.3.md","title":"Benchmarking -- Node 8.9.3","description":"Setup","date":"2024-03-13T09:34:49.000Z","formattedDate":"March 13, 2024","tags":[{"label":"benchmarking-reports","permalink":"/reports/tags/benchmarking-reports"}],"readingTime":2.69,"hasTruncateMarker":false,"authors":[{"name":"Michael Karg","title":"Performance and Tracing Team Lead","url":"https://github.com/mgmeier","imageURL":"https://github.com/mgmeier.png","key":"mgmeier"}],"frontMatter":{"title":"Benchmarking -- Node 8.9.3","slug":"2024-05-performance-8.9.3","authors":"mgmeier","tags":["benchmarking-reports"],"hide_table_of_contents":false},"prevItem":{"title":"Benchmarking -- Node 8.9.1","permalink":"/reports/2024-03-performance-8.9.1"},"nextItem":{"title":"Benchmarking -- Node 8.12.1","permalink":"/reports/2024-06-performance-8.12.1"}},"content":"## Setup\\n\\nAs part of the release benchmarking cycle, we\'re comparing benchmarking runs for 2 different versions of `cardano-node`:\\n* `8.9.1` - baseline from a previous mainnet release\\n* `8.9.3` - the current mainnet release\\n\\nFor each version, we\'re gathering various metrics under 2 different workloads:\\n1. _value-only_: Each transaction consumes 2 inputs and creates 2 outputs, changing the UTxO set. This workload produces full blocks (> 80kB) exclusively.\\n2. _Plutus_: Each transaction contains a Plutus script exhausting the per-tx execution budget. This workload produces small blocks (< 3kB) exclusively.\\n\\nBenchmarking is performed on a cluster of 52 block producing nodes spread across 3 different AWS regions, interconnected using a static, restricted topology. All runs\\nwere performed in the Babbage era.\\n\\n\\n## Observations\\n\\nThese benchmarks are about evaluating specific corner cases in a constrained environment that allows for reliable reproduction of results; they\'re not trying to directly recreate the operational conditions on Mainnet.  \\n\\n### Resource Usage\\n\\n1. Under value workload, CPU usage increases slightly on `8.9.3`: 4% for Process, 3% for Mutator and 8% for GC.\\n2. Additionally, Allocation rate and minor GCs increase slightly by 3% each.\\n3. Under Plutus workload only, the GC live dataset increases by 10% or 318MB.\\n4. CPU 85% spans increase by 14% of slot duration under value workload, whereas they shorten by 5% of slot duration under Plutus workload.\\n\\nCaveat: Individual metrics can\'t be evaluated in isolate; the resource usage profile as a whole provides insight into the system\'s performance and responsiveness.\\n\\n### Forging Loop\\n\\n1. There are no significant changes to metrics related to block forging.\\n\\nThe metric _\'Slot start to announced\'_ (see in attachments) is cumulative, and demonstrates how far into a slot the block producing node first announces the new header.\\n\\n### Peer propagation\\n\\n1. Block Fetch duration improves by 7ms (or 2%) under value workload, and by 4ms (or 3%) under Plutus workload.\\n2. Under Plutus workload, Fetched to sending improves by 2ms (or 5%).\\n\\n### End-to-end propagation\\n\\nThis metric encompasses block diffusion and adoption across specific percentages of the benchmarking cluster, with 0.80 adoption meaning adoption on 80% of all cluster nodes.  \\n\\n1. Under value workload, cluster adoption times exhibit a minor improvement (1%) up to the 80th centile on `8.9.3`.\\n2. Under Plutus workload, we can observe a minor improvement overall (1% - 2%), whilst full adoption is unchanged.\\n\\n\\n### Conclusion\\n\\n* The performance changes measured between `8.9.3` and `8.9.1` are very minor, with `8.9.3` improving slightly over `8.9.1`.\\n* Mainnnet performance of `8.9.3` is expected to be akin to `8.9.1`.\\n* We have not observed any performance regression being introduced in `8.9.3`.\\n\\n## Contact\\n\\nAs for publishing such benchmarking results, we are aware that more context and detail may be needed with regard to specfic metrics or benchmarking methodology. \\n\\nWe are still looking to gather questions, both general and specific, so that we can provide a suitable FAQ and possibly improve presentation in the future.\\n\\n## Attachments\\n\\nFull report for _value-only workload_, PDF downloadable [here](../static/pdf/benchmarking/release-8.9.3.value-only.pdf).\\n\\nFull report for _Plutus workload_, PDF downloadable [here](../static/pdf/benchmarking/release-8.9.3.plutus.pdf).\\n\\nNB. The baseline for `8.9.1` had to be re-established due to changes in the underlying network infrastructure. This means, absolute values may differ from the previous measurements taken from that version."},{"id":"2024-06-performance-8.12.1","metadata":{"permalink":"/reports/2024-06-performance-8.12.1","editUrl":"https://github.com/intersectmbo/cardano-updates/tree/main/reports/2024-06-performance-8.12.1.md","source":"@site/reports/2024-06-performance-8.12.1.md","title":"Benchmarking -- Node 8.12.1","description":"Setup","date":"2024-03-13T09:34:49.000Z","formattedDate":"March 13, 2024","tags":[{"label":"benchmarking-reports","permalink":"/reports/tags/benchmarking-reports"}],"readingTime":2.84,"hasTruncateMarker":false,"authors":[{"name":"Michael Karg","title":"Performance and Tracing Team Lead","url":"https://github.com/mgmeier","imageURL":"https://github.com/mgmeier.png","key":"mgmeier"}],"frontMatter":{"title":"Benchmarking -- Node 8.12.1","slug":"2024-06-performance-8.12.1","authors":"mgmeier","tags":["benchmarking-reports"],"hide_table_of_contents":false},"prevItem":{"title":"Benchmarking -- Node 8.9.3","permalink":"/reports/2024-05-performance-8.9.3"},"nextItem":{"title":"Benchmarking -- Node 9.0.0","permalink":"/reports/2024-07-performance-9.0.0"}},"content":"## Setup\\n\\nAs part of the release benchmarking cycle, we\'re comparing benchmarking runs for 2 different versions of `cardano-node`:\\n* `8.9.3` - baseline from a previous mainnet release\\n* `8.12.1` - the current mainnet release\\n\\nFor each version, we\'re gathering various metrics under 2 different workloads:\\n1. _value-only_: Each transaction consumes 2 inputs and creates 2 outputs, changing the UTxO set. This workload produces full blocks (> 80kB) exclusively.\\n2. _Plutus_: Each transaction contains a Plutus script exhausting the per-tx execution budget. This workload produces small blocks (< 3kB) exclusively.\\n\\nBenchmarking is performed on a cluster of 52 block producing nodes spread across 3 different AWS regions, interconnected using a static, restricted topology. All runs\\nwere performed in the Babbage era.\\n\\n\\n## Observations\\n\\nThese benchmarks are about evaluating specific corner cases in a constrained environment that allows for reliable reproduction of results; they\'re not trying to directly recreate the operational conditions on Mainnet.  \\n\\n### Resource Usage\\n\\n1. Under value workload, CPU usage is improved by 2% - 4%, and by 14% for GCs. Under Plutus workload, CPU usage improves only slightly by 1%.\\n2. Allocation Rate and Minor GCs improve by 5% and 6% - under Plutus workload, there\'s a slight improvement of 1%.\\n3. RAM usage is reduced by 3%; reduction under Plutus workload is even larger - namely 10%.\\n\\nCaveat: Individual metrics can\'t be evaluated in isolate; the resource usage profile as a whole provides insight into the system\'s performance and responsiveness.\\n\\n### Forging Loop\\n\\n1. Mempool snapshotting improves by 5ms or 7% (3ms or 4% under Plutus workload).\\n2. Adoption time on the block producer improves by 4ms or 6% - under value workload only.\\n\\nThe metric _\'Slot start to announced\'_ (see in attachments) is cumulative, and demonstrates how far into a slot the block producing node first announces the new header.\\n\\n### Peer propagation\\n\\n1. Block Fetch duration increases slightly by 6ms or 2% (2ms under Plutus workload).\\n2. Adoption times on the peers improve slightly by 2ms or 3% (1ms under Plutus workload)\\n\\n### End-to-end propagation\\n\\nThis metric encompasses block diffusion and adoption across specific percentages of the benchmarking cluster, with 0.80 adoption meaning adoption on 80% of all cluster nodes.  \\n\\n1. Under value workload / full blocks there are no significant changes to cluster adoption times.\\n2. Under Plutus workload / small blocks we can observe a (near-jitter) improvement of 0% - 2% in cluster adoption times.\\n\\n\\n### Conclusion\\n\\n* The performance changes measured between `8.12.1` and `8.9.3` are most distinct in the resource usage footprint - with `8.12.1` improving over `8.9.3`.\\n* On Mainnnet, `8.12.1` is expected to deliver equal or slightly better performance than `8.9.3` - as well as lowering the Node\'s resource usage somewhat in doing so.\\n* We have not observed any performance regression being introduced in `8.12.1`.\\n\\n## Contact\\n\\nAs for publishing such benchmarking results, we are aware that more context and detail may be needed with regard to specfic metrics or benchmarking methodology. \\n\\nWe are still looking to gather questions, both general and specific, so that we can provide a suitable FAQ and possibly improve presentation in the future.\\n\\n## Attachments\\n\\nFull report for _value-only workload_, PDF downloadable [here](../static/pdf/benchmarking/release-8.12.1.value-only.pdf).\\n\\nFull report for _Plutus workload_, PDF downloadable [here](../static/pdf/benchmarking/release-8.12.1.plutus.pdf).\\n\\nNB. The release benchmarks for `8.12.1` were performed on tag `8.12.0-pre`. The patch version bump did not include changes relevant to performance; thus, measurements taken on `8.12.0-pre` remain valid."},{"id":"2024-07-performance-9.0.0","metadata":{"permalink":"/reports/2024-07-performance-9.0.0","editUrl":"https://github.com/intersectmbo/cardano-updates/tree/main/reports/2024-07-performance-9.0.0.md","source":"@site/reports/2024-07-performance-9.0.0.md","title":"Benchmarking -- Node 9.0.0","description":"Setup","date":"2024-03-13T09:34:49.000Z","formattedDate":"March 13, 2024","tags":[{"label":"benchmarking-reports","permalink":"/reports/tags/benchmarking-reports"}],"readingTime":3.11,"hasTruncateMarker":false,"authors":[{"name":"Michael Karg","title":"Performance and Tracing Team Lead","url":"https://github.com/mgmeier","imageURL":"https://github.com/mgmeier.png","key":"mgmeier"}],"frontMatter":{"title":"Benchmarking -- Node 9.0.0","slug":"2024-07-performance-9.0.0","authors":"mgmeier","tags":["benchmarking-reports"],"hide_table_of_contents":false},"prevItem":{"title":"Benchmarking -- Node 8.12.1","permalink":"/reports/2024-06-performance-8.12.1"},"nextItem":{"title":"Benchmarking -- Node 9.2.0","permalink":"/reports/2024-09-performance-9.2.0"}},"content":"## Setup\\n\\nAs part of the release benchmarking cycle, we\'re comparing benchmarking runs for 2 different versions of `cardano-node`:\\n* `8.12.1` - baseline from a previous mainnet release\\n* `9.0.0` - the current mainnet release\\n\\nFor each version, we\'re gathering various metrics under 2 different workloads:\\n1. _value-only_: Each transaction consumes 2 inputs and creates 2 outputs, changing the UTxO set. This workload produces full blocks (> 80kB) exclusively.\\n2. _Plutus_: Each transaction contains a Plutus script exhausting the per-tx execution budget. This workload produces small blocks (< 3kB) exclusively.\\n\\nBenchmarking is performed on a cluster of 52 block producing nodes spread across 3 different AWS regions, interconnected using a static, restricted topology. All runs\\nwere performed in the Conway era.\\n\\n## Observations\\n\\nThese benchmarks are about evaluating specific corner cases in a constrained environment that allows for reliable reproduction of results; they\'re not trying to directly recreate the operational conditions on Mainnet.  \\n\\n### Resource Usage\\n\\n1. Under value workload Process and Mutator CPU usage are slightly higher on `9.0` - 7% - 8% (4% each under Plutus workload). GC CPU is increased by 11%, but decreases under Putus workload by 3%.\\n2. Only under value workload, Allocation Rate and Minor GCs increase by 5% and the live GC dataset grows by 3%. Heap size is constant.\\n3. CPU 85% spans are 8% shorter (3% under Plutus workload).\\n\\nCaveat: Individual metrics can\'t be evaluated in isolate; the resource usage profile as a whole provides insight into the system\'s performance and responsiveness.\\n\\n### Forging Loop\\n\\n1. Mempool Snapshotting and Self Adoption time on the block producer increase very slightly under value workload - 2ms (or 3%) each.\\n2. Under Plutus workload, however, a decrease in Self Adoption time by 2ms (or 4%) is the only significant change in the forging loop.\\n\\nThe metric _\'Slot start to announced\'_ (see in attachments) is cumulative, and demonstrates how far into a slot the block producing node first announces the new header.\\n\\n### Peer propagation\\n\\n1. Block Fetch duration is 21ms faster (6%) - 7ms or 5% under Plutus workload.\\n2. Fetched to Sending increases slightly by 3ms (7%) - only under value workload.\\n3. Adoption times on the peers increase slightly by 4ms (5%) - under Plutus workload, however, they are 3ms (6%) faster.\\n\\n### End-to-end propagation\\n\\nThis metric encompasses block diffusion and adoption across specific percentages of the benchmarking cluster, with 0.80 adoption meaning adoption on 80% of all cluster nodes.  \\n\\n1. Under value workload / full blocks on `9.0`, we can observe a 4% - 5% improvement of cluster adoption times in the 80th centile and above.\\n2. Under Plutus workload / small blocks, the corresponding improvement is 5% - 6%.\\n3. The main contributing factor is the improvement in Block Fetch duration.\\n\\n\\n### Conclusion\\n\\n* Network performance clearly improves by ~%5 for 80% to full cluster adoption - independent of workload.\\n* RAM usage is unchanged on `9.0`. The slight rise in CPU usage is expected, given improved network performance, and does not pose cause for concern.\\n* We have not observed any performance regression being introduced in `9.0.0.`.\\n\\nNB. These benchmarks were performed in the Conway ledger era. As such, they do not cover the one-time performance cost of transitioning from Babbage and enabling the new features of the Conway ledger.\\n\\n## Contact\\n\\nAs for publishing such benchmarking results, we are aware that more context and detail may be needed with regard to specfic metrics or benchmarking methodology. \\n\\nWe are still looking to gather questions, both general and specific, so that we can provide a suitable FAQ and possibly improve presentation in the future.\\n\\n## Attachments\\n\\nFull report for _value-only workload_, PDF downloadable [here](../static/pdf/benchmarking/release-9.0.0.value-only.pdf).\\n\\nFull report for _Plutus workload_, PDF downloadable [here](../static/pdf/benchmarking/release-9.0.0.plutus.pdf)."},{"id":"2024-09-performance-9.2.0","metadata":{"permalink":"/reports/2024-09-performance-9.2.0","editUrl":"https://github.com/intersectmbo/cardano-updates/tree/main/reports/2024-09-performance-9.2.0.md","source":"@site/reports/2024-09-performance-9.2.0.md","title":"Benchmarking -- Node 9.2.0","description":"Setup","date":"2024-03-13T09:34:49.000Z","formattedDate":"March 13, 2024","tags":[{"label":"benchmarking-reports","permalink":"/reports/tags/benchmarking-reports"}],"readingTime":2.93,"hasTruncateMarker":false,"authors":[{"name":"Michael Karg","title":"Performance and Tracing Team Lead","url":"https://github.com/mgmeier","imageURL":"https://github.com/mgmeier.png","key":"mgmeier"}],"frontMatter":{"title":"Benchmarking -- Node 9.2.0","slug":"2024-09-performance-9.2.0","authors":"mgmeier","tags":["benchmarking-reports"],"hide_table_of_contents":false},"prevItem":{"title":"Benchmarking -- Node 9.0.0","permalink":"/reports/2024-07-performance-9.0.0"},"nextItem":{"title":"Benchmarking -- Node 8.7.2","permalink":"/reports/2023-12-performance-8.7.2"}},"content":"## Setup\\n\\nAs part of the release benchmarking cycle, we\'re comparing benchmarking runs for 2 different versions of `cardano-node`:\\n* `9.1.1` - baseline from a previous mainnet release\\n* `9.2.0` - the current mainnet release\\n\\nFor each version, we\'re gathering various metrics under 2 different workloads:\\n1. _value-only_: Each transaction consumes 2 inputs and creates 2 outputs, changing the UTxO set. This workload produces full blocks (> 80kB) exclusively.\\n2. _Plutus_: Each transaction contains a Plutus script exhausting the per-tx execution budget. This workload produces small blocks (< 3kB) exclusively.\\n\\nBenchmarking is performed on a cluster of 52 block producing nodes spread across 3 different AWS regions, interconnected using a static, restricted topology. All runs\\nwere performed in the Conway era.\\n\\n## Observations\\n\\nThese benchmarks are about evaluating specific corner cases in a constrained environment that allows for reliable reproduction of results; they\'re not trying to directly recreate the operational conditions on Mainnet.  \\n\\n### Resource Usage\\n\\n1. Under value workload, `9.2.0` shows an increase by 7% in Process CPU usage.\\n2. Additionally, Allocation Rate and Minor GCs increase by 6% each, while Heap Size remains unchanged.\\n3. Furthermore, CPU 85% spans increase by 10%.\\n4. Under Plutus workload however, there\'s just one significant observation: a larger portion of the heap is considered live (6% or ~190MB) with the overall Heap Size remaining constant.\\n\\nCaveat: Individual metrics can\'t be evaluated in isolate; the resource usage profile as a whole provides insight into the system\'s performance and responsiveness.\\n\\n### Forging Loop\\n\\n1. For the forger metrics, we can observe minor (1ms - 2ms) improvements in Ledger Ticking, Mempool Snapshotting and Self Adoption under value workload.\\n2. Under Plutus workload, there are minor (1ms - 2ms) increases in Ledger Ticking and Mempool Snapshotting.\\n\\nThe metric _\'Slot start to announced\'_ (see in attachments) is cumulative, and demonstrates how far into a slot the block producing node first announces the new header.\\n\\n### Peer propagation\\n\\n1. Block Fetch duration has improved by 11ms (or 3%) under value workload.\\n2. Under Plutus workload, peer Adoption times are slightly increased by 2ms (3%).\\n\\n### End-to-end propagation\\n\\nThis metric encompasses block diffusion and adoption across specific percentages of the benchmarking cluster, with 0.80 adoption meaning adoption on 80% of all cluster nodes.  \\n\\n1. Under value workload / full blocks, `9.2.0` exhibits a slight improvement of 1% - 3% in cluster adoption times.\\n2. Under Plutus workload / small blocks, there\'s a very minor increase by 1%.\\n\\n### Conclusion\\n\\n* We can not detect any perfomance regression in `9.2.0` compared to `9.1.1`.\\n* Under heavy value workload, `9.2.0` seems to perform work somewhat more eagerly. This would correlate with the slightly increased CPU usage, but also with the improvements in the forging and peer related metrics.\\n* The clearly increased efficiency of Block Fetch under heavy workload is the main contributing factor to the slight overall network performance improvement.\\n\\nNB. These benchmarks were performed using an adjusted, post-Chang hardfork performance baseline to account for added features in the Conway ledger era. Thus, absolute measurements might differ now from those taken using the previous baseline.\\n\\n## Contact\\n\\nAs for publishing such benchmarking results, we are aware that more context and detail may be needed with regard to specfic metrics or benchmarking methodology. \\n\\nWe are still looking to gather questions, both general and specific, so that we can provide a suitable FAQ and possibly improve presentation in the future.\\n\\n## Attachments\\n\\nFull report for _value-only workload_, PDF downloadable [here](../static/pdf/benchmarking/release-9.2.0.value-only.pdf).\\n\\nFull report for _Plutus workload_, PDF downloadable [here](../static/pdf/benchmarking/release-9.2.0.plutus.pdf)."},{"id":"2023-12-performance-8.7.2","metadata":{"permalink":"/reports/2023-12-performance-8.7.2","editUrl":"https://github.com/intersectmbo/cardano-updates/tree/main/reports/2023-12-performance-8.7.2.md","source":"@site/reports/2023-12-performance-8.7.2.md","title":"Benchmarking -- Node 8.7.2","description":"Setup","date":"2023-12-08T15:38:20.000Z","formattedDate":"December 8, 2023","tags":[{"label":"benchmarking-reports","permalink":"/reports/tags/benchmarking-reports"}],"readingTime":2.76,"hasTruncateMarker":false,"authors":[{"name":"Michael Karg","title":"Performance and Tracing Team Lead","url":"https://github.com/mgmeier","imageURL":"https://github.com/mgmeier.png","key":"mgmeier"}],"frontMatter":{"title":"Benchmarking -- Node 8.7.2","slug":"2023-12-performance-8.7.2","authors":"mgmeier","tags":["benchmarking-reports"],"hide_table_of_contents":false},"prevItem":{"title":"Benchmarking -- Node 9.2.0","permalink":"/reports/2024-09-performance-9.2.0"}},"content":"## Setup\\n\\nAs part of the release benchmarking cycle, we\'re comparing benchmarking runs for 3 different versions of `cardano-node`:\\n* `8.1.2` - the last mainnet release\\n* `8.7.0-pre` - as an intermediate reference point\\n* `8.7.2` - the next mainnet release\\n\\nFor each version, we\'re gathering various metrics under 2 different workloads:\\n1. _value-only_: Each transaction consumes 2 inputs and creates 2 outputs, changing the UTxO set. This workload produces full blocks (> 80kB) exclusively.\\n2. _Plutus_: Each transaction contains a Plutus script exhausting the per-tx execution budget. This workload produces small blocks (< 3kB) exclusively.\\n\\nBenchmarking is performed on a cluster of 52 block producing nodes spread across 3 different AWS regions, interconnected using a static, restricted topology. All runs\\nwere performed in the Babbage era.\\n\\n\\n## Observations\\n\\nThese benchmarks are about evaluating specific corner cases in a constrained environment that allows for reliable reproduction of results; they\'re not trying to directly recreate the operational conditions on Mainnet.  \\n\\nThe observations stated refer to the direct comparison between the `8.1.2` and `8.7.2` versions.\\n\\n### Resource Usage\\n\\n1. Plutus workload, having a lower overall absolute CPU load, exhibits an average increase of 27% in Process CPU usage. Value workload, having a higher overall absolute CPU load, exhibits a near-jitter increase of 1%.\\n2. Allocation rates increase by ~8.9MB/s (value workload) and ~12.6MB/s (Plutus workload).\\n3. Heap sizes increase by 47% - 54%.\\n4. CPU 85% span duration shrinks by ~9.7 slots under value workload, and ~5.8 slots under Pluts workload.\\n\\nCaveat: Individual metrics can\'t be evaluated in isolate; the resource usage profile as a whole provides insight into the system\'s performance and responsiveness.\\n\\n\\n### Forging Loop\\n\\n1. Block Context Acquisition in the forging loop increases by ~10ms.\\n2. Mempool snapshotting shows an increase by 16ms under value workload; under Plutus workload, it increases by 3ms.\\n3. Ledger ticking improves slightly by 1-2ms.\\n\\nThe metric _\'Slot start to announced\'_ (see in attachements) is cumulative, and demonstrates how far into a slot the block producing node first announces the new header.\\n\\n### Peer propagation\\n\\n1. Block fetch time increases for full blocks by 9%. For small blocks, it improves by 7%.\\n2. Time to resend a block after fetching increases by 8% for full blocks, whereas it improves by 2% for small blocks.\\n3. Block adoption by a peer takes 12% more time for a full block, but happens faster by 4% for a small block.\\n\\n### End-to-end propagation\\n\\nThis metric encompasses block diffusion and adoption across specific percentages of the benchmarking cluster, with 0.80 adoption meaning adoption on 80% of all cluster nodes.\\n\\nThe metric exhibits an increase by ~10% across all centiles for full blocks, whereas it improves by 5-6% for small blocks in the higher (80th and above) centiles.\\n\\n## Contact\\n\\nThis is the first time we\'re publishing, to a wider audience, such benchmarking results. We are aware that more context and detail may be needed with regard to specfic metrics or benchmarking methodology. \\n\\nWe are looking to gather questions, both general and specific, so that we can provide a suitable FAQ and possibly improve presentation in the future.\\n\\n## Attachments\\n\\nFull report for _value-only workload_, PDF downloadable [here](../static/pdf/benchmarking/8.7.1_8.1.2_8.7.0-pre_8.7.1-pre.value-only.pdf).\\n\\nFull report for _Plutus workload_, PDF downloadable [here](../static/pdf/benchmarking/8.7.1_8.1.2_8.7.0-pre_8.7.1-pre.plutus.pdf).\\n\\nThe relese benchmarks for `8.7.2` were performed on tag `8.7.1-pre`, which features identical `cardano-node` components."}]}')}}]);