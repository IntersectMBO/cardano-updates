"use strict";(self.webpackChunkcardano_updates=self.webpackChunkcardano_updates||[]).push([[28810],{42013:e=>{e.exports=JSON.parse('{"blogPosts":[{"id":"2026-02-performance-10.6.2","metadata":{"permalink":"/reports/2026-02-performance-10.6.2","editUrl":"https://github.com/intersectmbo/cardano-updates/tree/main/reports/2026-02-performance-10.6.2.md","source":"@site/reports/2026-02-performance-10.6.2.md","title":"Benchmarking -- Node 10.6.2","description":"Setup","date":"2026-02-19T11:24:55.000Z","formattedDate":"February 19, 2026","tags":[{"label":"benchmarking-reports","permalink":"/reports/tags/benchmarking-reports"}],"readingTime":3.53,"hasTruncateMarker":false,"authors":[{"name":"Michael Karg","title":"Performance and Tracing Team Lead","url":"https://github.com/mgmeier","imageURL":"https://github.com/mgmeier.png","key":"mgmeier"}],"frontMatter":{"title":"Benchmarking -- Node 10.6.2","slug":"2026-02-performance-10.6.2","authors":"mgmeier","tags":["benchmarking-reports"],"hide_table_of_contents":false},"nextItem":{"title":"Benchmarking -- Node 10.5.4","permalink":"/reports/2026-02-performance-10.5.4"}},"content":"## Setup\\n\\nAs part of the release benchmarking cycle, we\'re comparing benchmarking runs for 2 different versions of `cardano-node`:\\n* `10.5.4` - the current Node 10.5 Mainnet release\\n* `10.6.2` - the current Node 10.6 Mainnet release\\n\\nFor this benchmark, we\'re gathering various metrics under 2 different workloads:\\n1. _value-only_: Each txn consumes 2 inputs and creates 2 outputs, changing the UTxO set. Full blocks (> 80kB) exclusively; high submission pressure (TPS > 10).\\n2. _Plutus_: Each txn contains a Plutus script exhausting the per-tx execution budget. Small blocks (< 3kB) exclusively; low submission pressure (TPS < 1).\\n\\nBenchmarking is performed on a cluster of 52 block producing nodes spread across 3 different AWS regions, interconnected using a static, restricted topology. All runs\\nwere performed in the Conway era.  \\n\\n\\n## Observations\\n\\nThese benchmarks are about evaluating specific corner cases in a constrained environment that allows for reliable reproduction of results; they\'re not trying to directly recreate the operational conditions on Mainnet.  \\n\\n### Resource Usage\\n\\n1. `10.6.2` exhibits a clear 6% _reduction_ in Process CPU usage under full saturation workload, and a 2% _reduction_ under Plutus workload.\\n2. Allocation rate and Minor GCs are significantly _reduced_ as well (~59% and 64% depending on workload).\\n3. Major GC events _go up_ by 27% and 34%, depending on workload.\\n4. Observed CPU 85% spans exhibit a clear _increase_ in duration -- ~4.1 and ~1.8 slots depending on workload.\\n5. RAM usage decreases by 19% and 24% depending on workload. **HOWEVER**: This is a known result of optimizations in the benchmarking setup. From a seperate benchmark with those optimizations applied on top of `10.5`, we know that `10.6.2` exhibits a very minor _increase_ (1% - 2%) in average Heap size, with a _reduction_ in maximum Heap size under saturation workload only.\\n\\nCaveat: Individual metrics can\'t be evaluated in isolate; the resource usage profile as a whole provides insight into the system\'s performance and responsiveness.\\n\\n### Forging Loop\\n\\n1. We can observe Ledger Ticking _decrease_ by 3ms - 5ms.\\n2. Under saturation workload only, Mempool snapshotting and Forged to Sending exhibit small _increases_ by 2ms each.\\n3. As a result, a block producer is able to announce a new header 2ms - 3ms _earlier_ into a slot (depending on workload).\\n4. Self adoption on the forging node also _decreases_ by 2ms - 3ms.\\n\\nThe metric _\'Slot start to announced\'_ (see in attachments) is cumulative, and demonstrates how far into a slot the block producing node first announces the new header.\\n\\n### Peer propagation\\n\\n1. Block Fetch duration _decreases_ by 2% (3ms or 5ms, depending on workload).\\n2. For small blocks, Adoption times on the peers _increase_ by 2ms, however, for large blocks they _decrease_ by 3ms.\\n\\n### End-to-end propagation\\n\\nThis metric encompasses block diffusion and adoption across specific percentages of the benchmarking cluster, with 0.80 adoption meaning adoption on 80% of all cluster nodes.  \\n\\n1. Cluster adoption metrics on `10.6.2` exhibit no significant change under high submission / large blocks workload.\\n2. Under low submission / small blocks workload, there are _small improvements_ of 1% - 3% in the body of the distribution, and a 10% _increase_ in the 100th centile.\\n\\n### Conclusion\\n\\n1. `10.6.2` is more efficient in its usage of CPU time. Considered in conjunction with the increase in CPU 85% spans, it points to a redistribution of work which results in less bursts, and more plateaus.\\n2. Seeing there is no negative impact on block production and diffusion metrics, and considering the overall decrease in CPU usage, the CPU 85% span increase can\'t be interpreted as a risk to performance or responsiveneess.\\n3. The RAM increase observed on `10.6.0-pre` has been successfully fixed in `10.6.2`.\\n4. `10.6.2` is more efficient wrt. block production and diffusion.\\n5. Adoption metrics are largely equivalent to `10.5.4`; the 10% increase in the Plutus workload\'s 100th centile is an outlier resulting from the benchmark\'s very restrictive topology. Unless the increase also manifests in the 98th and 96th centiles, or below, it is not considered a risk.\\n6. From a performance perspective, we can determine `10.6.2` to be regression-free and attest a clean bill of health.\\n\\n## Attachments\\n\\nFull comparison for _value-only workload_, PDF downloadable [here](../static/pdf/benchmarking/release-10.6.2.value-only.pdf).\\n\\nFull comparison for _Plutus workload_, PDF downloadable [here](../static/pdf/benchmarking/release-10.6.2.plutus.pdf)."},{"id":"2026-02-performance-10.5.4","metadata":{"permalink":"/reports/2026-02-performance-10.5.4","editUrl":"https://github.com/intersectmbo/cardano-updates/tree/main/reports/2026-02-performance-10.5.4.md","source":"@site/reports/2026-02-performance-10.5.4.md","title":"Benchmarking -- Node 10.5.4","description":"Setup","date":"2026-02-09T17:19:04.000Z","formattedDate":"February 9, 2026","tags":[{"label":"benchmarking-reports","permalink":"/reports/tags/benchmarking-reports"}],"readingTime":2.45,"hasTruncateMarker":false,"authors":[{"name":"Michael Karg","title":"Performance and Tracing Team Lead","url":"https://github.com/mgmeier","imageURL":"https://github.com/mgmeier.png","key":"mgmeier"}],"frontMatter":{"title":"Benchmarking -- Node 10.5.4","slug":"2026-02-performance-10.5.4","authors":"mgmeier","tags":["benchmarking-reports"],"hide_table_of_contents":false},"prevItem":{"title":"Benchmarking -- Node 10.6.2","permalink":"/reports/2026-02-performance-10.6.2"},"nextItem":{"title":"Memory Budget Scaling -- 10.6","permalink":"/reports/2026-01-execbudget-memory-10.6"}},"content":"## Setup\\n\\nAs part of the release benchmarking cycle, we\'re comparing benchmarking runs for 2 different versions of `cardano-node`:\\n* `10.5-baseline` - performance baseline from previous Node 10.5 releases\\n* `10.5.4` - the current Node 10.5.4 release\\n\\nFor this benchmark, we\'re gathering various metrics under 2 different workloads:\\n1. _value-only_: Each transaction consumes 2 inputs and creates 2 outputs, changing the UTxO set. This workload produces full blocks (> 80kB) exclusively.\\n2. _Plutus_: Each transaction contains a Plutus script exhausting the per-tx execution budget. This workload produces small blocks (< 3kB) exclusively.\\n\\nBenchmarking is performed on a cluster of 52 block producing nodes spread across 3 different AWS regions, interconnected using a static, restricted topology. All runs\\nwere performed in the Conway era.  \\n\\n\\n## Observations\\n\\nThese benchmarks are about evaluating specific corner cases in a constrained environment that allows for reliable reproduction of results; they\'re not trying to directly recreate the operational conditions on Mainnet.  \\n\\n### Resource Usage\\n\\n1. `10.5.4` exhibits a slight 3% _increase_ in Process CPU usage -- regardless of workload type.\\n2. RAM usage _decreases_ slightly by 3% (0.23GiB - 0.26GiB, depending on workload).\\n3. Observed CPU 85% span duration exhibits a very faint _increase_ -- between ~0.25 and ~0.35 slots.\\n\\nCaveat: Individual metrics can\'t be evaluated in isolate; the resource usage profile as a whole provides insight into the system\'s performance and responsiveness.\\n\\n### Forging Loop\\n\\n1. For large blocks only, we can observe a small _increase_ in Adoption time by 2ms.\\n2. Beyond that, there are no significant changes to block production metrics.\\n\\nThe metric _\'Slot start to announced\'_ (see in attachments) is cumulative, and demonstrates how far into a slot the block producing node first announces the new header.\\n\\n### Peer propagation\\n\\n1. For large blocks, average Block Fetch duration _decreases_ by 2ms, but Adoption times on the peers _increase_ by 2ms.\\n2. For small blocks, average Block Fetch duration _increases_ by 5ms, but Adoption times on the peers _decrease_ by 3ms.\\n\\n### End-to-end propagation\\n\\nThis metric encompasses block diffusion and adoption across specific percentages of the benchmarking cluster, with 0.80 adoption meaning adoption on 80% of all cluster nodes.  \\n\\n1. Cluster adoption metrics on `10.5.4` exhibit no significant change under high submission / large blocks workload.\\n2. Under Plutus workload (low submission / small blocks), there\'s a minor _increase_ by 2% - 3% between the 80th and 98th centiles.\\n\\n### Conclusion\\n\\n1. The small up and down changes in Adoption times and Block fetch duration are well within margin of slack and do not pose any kind of performance risk.\\n2. Transitively, this applies to observed E2E propagation metrics as well.\\n3. All in all, `10.5.4` is pretty closely aligned with the existing 10.5 performance baseline.\\n4. From a performance perspective, we can determine it to be regression-free and attest a clean bill of health.\\n\\n## Attachments\\n\\nFull comparison for _value-only workload_, PDF downloadable [here](../static/pdf/benchmarking/release-10.5.4.value-only.pdf).\\n\\nFull comparison for _Plutus workload_, PDF downloadable [here](../static/pdf/benchmarking/release-10.5.4.plutus.pdf)."},{"id":"2026-01-execbudget-memory-10.6","metadata":{"permalink":"/reports/2026-01-execbudget-memory-10.6","editUrl":"https://github.com/intersectmbo/cardano-updates/tree/main/reports/2026-01-execbudget-memory-10.6.md","source":"@site/reports/2026-01-execbudget-memory-10.6.md","title":"Memory Budget Scaling -- 10.6","description":"Setup","date":"2026-01-20T11:22:43.000Z","formattedDate":"January 20, 2026","tags":[{"label":"benchmarking-reports","permalink":"/reports/tags/benchmarking-reports"}],"readingTime":3.6,"hasTruncateMarker":false,"authors":[{"name":"Michael Karg","title":"Performance and Tracing Team Lead","url":"https://github.com/mgmeier","imageURL":"https://github.com/mgmeier.png","key":"mgmeier"}],"frontMatter":{"title":"Memory Budget Scaling -- 10.6","slug":"2026-01-execbudget-memory-10.6","authors":"mgmeier","tags":["benchmarking-reports"],"hide_table_of_contents":false},"prevItem":{"title":"Benchmarking -- Node 10.5.4","permalink":"/reports/2026-02-performance-10.5.4"},"nextItem":{"title":"Benchmarking -- Node 10.6.0-pre","permalink":"/reports/2025-11-performance-10.6.0-pre"}},"content":"## Setup\\n\\nThis report compares benchmarking runs for 3 different settings of the Plutus memory execution budget:\\n* `10.6.1-jan26` - current mainnet memory execution budget\\n* `mem-x1.5` - 1.5 x current mainnet memory execution budget\\n* `mem-x2` - 2 x current mainnet memory execution budget\\n\\nFor this comparison, we gather various metrics under the _Plutus_ workload used in release benchmarks: Each block produced during the benchmark contains\\n4 identical script transactions calibrated to fully exhaust the memory execution budget. Thus, script execution is constrained by the memory budget limit\\nevery case. The workload produces small blocks (< 3kB) exclusively.  \\n\\nBenchmarking is performed on a cluster of 52 block producing nodes spread across 3 different AWS regions, interconnected using a static, restricted topology. \\n\\nIdentical scaling benchmarks were performed in Q1 2025 on [Node 10.2 / GHC8.10] and [Node 10.3 / GHC9.6]. This comparison aims to ascertain the past observations and conclusions still apply,\\ngiven the most recent Node version (10.6.1, with patches for 10.6.2 backported) and its recommended compiler version GHC9.6.7.\\n\\n\\n## Observations\\n\\n### Resource Usage\\n\\n1. Scaling the memory budget impacts Allocation Rate and Minor GCs. 1.5 x the budget results in rises of 21% - 22%; for doubling the budget the corresponding rises are 36% - 38%.\\n2. These increases exhibit a slightly sublinear correlation with raising mem budget; however, in absolute terms they are much steeper (roughly 4x) compared to Node 10.3.\\n3. The Node process RAM footprint is unaffected by and the effects on Process CPU usage is negligible for either scaling factor.\\n4. CPU 85% span duration exhibits a slight constant increase (approx. 0.5 slots) when scaling the mem budget, regardless of the factor.\\n\\nCaveat: Individual metrics can\'t be evaluated in isolate; the resource usage profile as a whole provides insight into the system\'s performance and responsiveness.\\n\\n### Forging Loop\\n\\n1. Scaling the memory budget has significant impact on self adoption time only.\\n2. Scaling by factor 1.5 leads to an 11ms (or 25%) increase, whereas factor 2 leads to 22ms (51%); this is fully congruent with the observations on Node 10.3.\\n3. This increase is linearly correlated with raising the mem budget.\\n4. With increased memory budget, counterintuitively, the time from slot start until new header announcement *decreases* slightly - by 4ms (factor 1.5) and 2ms (factor 2). This was not observed on Node 10.3.\\n\\n### Peer propagation\\n\\n1. Same as on the block producer, scaling the memory budget has significant impact on block adoption times only.\\n2. Scaling by factor 1.5 leads to an 10ms (or 22%) increase, whereas factor 2 leads to 17ms (37%).\\n3. Again, these increases exhibit a slightly sublinear correlation with raising the mem budget - largely congruent with the absolute increases seen on Node 10.3.\\n   \\n### End-to-end propagation\\n\\nThis metric encompasses block diffusion and adoption across specific percentages of the benchmarking cluster, with 0.80 adoption meaning adoption on 80% of all cluster nodes.  \\n\\n1. 1.5 x the memory budget results in a minor increase of 2ms - 16ms in cluster adoption times (1% - 3%).\\n2. 2 x the memory budget results in a slight 10ms - 13ms increase (2% - 3%).\\n3. These increases are clearly lower (very roughly 2.5x) than those observed on Node 10.3.\\n\\n### Conclusion\\n\\nThese measurements outline the headroom for raising the memory budget, along with the expected performance impact:\\n1. Block adoption time is the only network metric that\'s affected significantly, increasing both on the forger and the peers by the same extent.\\n2. These increases seem to correspond linearly at worst with raising the memory budget. This gives excellent predictability of performance impact up to a hypothetical 100% raise.\\n3. Expectedly, more allocations and minor GCs take place; however, CPU and RAM usage remain nearly constant.\\n4. Block diffusion is only marginally affected by changing the execution budget: Due to header pipelining, announcing and (re-)sending a block precedes adoption in most cases.\\n5. As such, measurements taken with either budget adjustment *do not indicate performance risks* to the network, but clearly evidence their respective performance cost.\\n6. With the exception of extra allocations, all measurements point to a recent Node version delivering equal or slightly better performance compared to 10.3 given some memory budget increase.\\n\\n## Attachment\\n\\nFull report PDF downloadable [here](../static/pdf/benchmarking/execbudget-10.6-mem_scaling.pdf).\\n\\n[Node 10.2 / GHC8.10]: https://updates.cardano.intersectmbo.org/reports/2025-03-execbudget-memory-10.2\\n[Node 10.3 / GHC9.6]: https://updates.cardano.intersectmbo.org/reports/2025-05-execbudget-memory-10.3"},{"id":"2025-11-performance-10.6.0-pre","metadata":{"permalink":"/reports/2025-11-performance-10.6.0-pre","editUrl":"https://github.com/intersectmbo/cardano-updates/tree/main/reports/2025-11-performance-10.6.0-pre.md","source":"@site/reports/2025-11-performance-10.6.0-pre.md","title":"Benchmarking -- Node 10.6.0-pre","description":"Setup","date":"2025-11-21T10:36:00.000Z","formattedDate":"November 21, 2025","tags":[{"label":"benchmarking-reports","permalink":"/reports/tags/benchmarking-reports"}],"readingTime":2.805,"hasTruncateMarker":false,"authors":[{"name":"Michael Karg","title":"Performance and Tracing Team Lead","url":"https://github.com/mgmeier","imageURL":"https://github.com/mgmeier.png","key":"mgmeier"}],"frontMatter":{"title":"Benchmarking -- Node 10.6.0-pre","slug":"2025-11-performance-10.6.0-pre","authors":"mgmeier","tags":["benchmarking-reports"],"hide_table_of_contents":false},"prevItem":{"title":"Memory Budget Scaling -- 10.6","permalink":"/reports/2026-01-execbudget-memory-10.6"},"nextItem":{"title":"Benchmarking -- Node 10.5.0","permalink":"/reports/2025-07-performance-10.5.0"}},"content":"## Setup\\n\\nAs part of the release benchmarking cycle, we\'re comparing benchmarking runs for 2 different versions of `cardano-node`:\\n* `10.5` - baseline from the previous Node release\\n* `10.6.0-pre` - the current (pre-)release tag\\n\\nFor this benchmark, we\'re gathering various metrics under 2 different workloads:\\n1. _value-only_: Each transaction consumes 2 inputs and creates 2 outputs, changing the UTxO set. This workload produces full blocks (> 80kB) exclusively.\\n2. _Plutus_: Each transaction contains a Plutus script exhausting the per-tx execution budget. This workload produces small blocks (< 3kB) exclusively.\\n\\nBenchmarking is performed on a cluster of 52 block producing nodes spread across 3 different AWS regions, interconnected using a static, restricted topology. All runs\\nwere performed in the Conway era.  \\n\\n\\n## Observations\\n\\nThese benchmarks are about evaluating specific corner cases in a constrained environment that allows for reliable reproduction of results; they\'re not trying to directly recreate the operational conditions on Mainnet.  \\n\\n### Resource Usage\\n\\n1. `10.6.0-pre` exhibits a slight shift in CPU usage. It consumes 3% _less_ CPU time under saturation, whereas under a low submission workload it consumes 4% _more_.\\n2. Allocation rate and Minor GCs impact are significantly _reduced_ - (~45% and ~59% depending on workload). This takes much pressure away from the garbage collector.\\n3. RAM usage _increases_ significantly by 0.9GiB - 1.1GiB (15% - 17% depending on workload).\\n4. Observed CPU 85% spans are _longer_ -- ~3.1 slots under value and ~1.6 slots under Plutus workload.\\n\\nCaveat: Individual metrics can\'t be evaluated in isolate; the resource usage profile as a whole provides insight into the system\'s performance and responsiveness.\\n\\n### Forging Loop\\n\\n1. We can observe slight _increases_ in Ledger Ticking and Mempool Snapshotting by 2ms each.\\n2. This causes a block producer to announce a new header 3ms - 4ms (or 6% - 12%) later into a slot.\\n3. Additionally, Adoption time on the block producer also increases by 3ms - 4ms.\\n\\nThe metric _\'Slot start to announced\'_ (see in attachments) is cumulative, and demonstrates how far into a slot the block producing node first announces the new header.\\n\\n### Peer propagation\\n\\n1. Under saturation workload only, Block Fetch duration increases by 7ms (or 2%).\\n2. Adoption times on the peers increase by 2ms - 3ms.\\n\\n### End-to-end propagation\\n\\nThis metric encompasses block diffusion and adoption across specific percentages of the benchmarking cluster, with 0.80 adoption meaning adoption on 80% of all cluster nodes.  \\n\\n1. Cluster adoption metrics on `10.6.0-pre` exhibit a small 2% - 3% increase across all centiles.\\n2. Under Plutus workload only, the increase becomes superlinear in 98th-100th centiles, with an extra 89ms (or 18%) required for full cluster adoption.\\n\\n### Conclusion\\n\\n1. The small increases in block production, diffusion and adoption metrics do not pose a performance risk to the network.\\n2. The restricted topology of the benchmark forces a regression in the tail end of the adoption metrics distribution to surface; in a live network, this is mitigated by a much higher number of connected peers / peer sharing.\\n3. The increase in RAM usage has so far not manifested on relay nodes deployed in a live network; as this is a pre-relase, the precise effect of our benchmark (exposing block producers to high pressure over extended time) is under investigation.\\n\\n## Attachments\\n\\nFull comparison for _value-only workload_, PDF downloadable [here](../static/pdf/benchmarking/release-10.6.0-pre.value-only.pdf).\\n\\nFull comparison for _Plutus workload_, PDF downloadable [here](../static/pdf/benchmarking/release-10.6.0-pre.plutus.pdf)."},{"id":"2025-07-performance-10.5.0","metadata":{"permalink":"/reports/2025-07-performance-10.5.0","editUrl":"https://github.com/intersectmbo/cardano-updates/tree/main/reports/2025-07-performance-10.5.0.md","source":"@site/reports/2025-07-performance-10.5.0.md","title":"Benchmarking -- Node 10.5.0","description":"Setup","date":"2025-07-02T09:50:10.000Z","formattedDate":"July 2, 2025","tags":[{"label":"benchmarking-reports","permalink":"/reports/tags/benchmarking-reports"}],"readingTime":3.35,"hasTruncateMarker":false,"authors":[{"name":"Michael Karg","title":"Performance and Tracing Team Lead","url":"https://github.com/mgmeier","imageURL":"https://github.com/mgmeier.png","key":"mgmeier"}],"frontMatter":{"title":"Benchmarking -- Node 10.5.0","slug":"2025-07-performance-10.5.0","authors":"mgmeier","tags":["benchmarking-reports"],"hide_table_of_contents":false},"prevItem":{"title":"Benchmarking -- Node 10.6.0-pre","permalink":"/reports/2025-11-performance-10.6.0-pre"},"nextItem":{"title":"Benchmarking -- Node 10.4.1","permalink":"/reports/2025-05-performance-10.4.1"}},"content":"## Setup\\n\\nAs part of the release benchmarking cycle, we\'re comparing benchmarking runs for 2 different versions of `cardano-node`:\\n* `10.4.1` - baseline from the previous Node release\\n* `10.5.0` - the current (pre-)release tag\\n\\nFor this benchmark, we\'re gathering various metrics under 2 different workloads:\\n1. _value-only_: Each transaction consumes 2 inputs and creates 2 outputs, changing the UTxO set. This workload produces full blocks (> 80kB) exclusively.\\n2. _Plutus_: Each transaction contains a Plutus script exhausting the per-tx execution budget. This workload produces small blocks (< 3kB) exclusively.\\n\\nBenchmarking is performed on a cluster of 52 block producing nodes spread across 3 different AWS regions, interconnected using a static, restricted topology. All runs\\nwere performed in the Conway era.  \\n\\n## Preliminaries\\n\\n1. The feature in `10.5` with major performance impact is periodic [ledger metrics]. This is exclusive to the [new tracing system].\\n2. `10.5` flips the default config for `PeerSharing` to `true`; however, the recommendation is to explicitly set it to `false` on block producers. If not for privacy issues alone, we also found disadvantageous performance impact on block production when enabled. Hence, our benchmarks do not factor in that overhead.\\n\\n## Observations\\n\\nThese benchmarks are about evaluating specific corner cases in a constrained environment that allows for reliable reproduction of results; they\'re not trying to directly recreate the operational conditions on Mainnet.  \\n\\n### Resource Usage\\n\\n1. `10.5.0` shows a clear reduction in CPU usage - by ~30% regardless of workload type.\\n2. Furthermore, Allocation rate and GC impact are clearly reduced - by 27%-29% and 24%-25% respectively.\\n3. Heap size _increases_ very slightly under saturation (by 1%) and _decreases_ very slightly (by 1%) under Plutus workload.\\n4. CPU 85% spans are slightly _shorter_ (~0.2 slots) under saturation, and slightly _longer_ (~0.26 slots) under Plutus workload.\\n\\nCaveat: Individual metrics can\'t be evaluated in isolate; the resource usage profile as a whole provides insight into the system\'s performance and responsiveness.\\n\\n### Forging Loop\\n\\n1. Block Context Acquisition time (prior to leadership check) is greatly reduced - from ~24ms to under 1ms.\\n2. Under saturation only, Ledger Ticking and Mempool Snapshotting exhibit very slight upticks (by 3ms and 2ms respectively).\\n3. Under Plutus workload only, Self Adoption on the forger exhibits a very slight uptick (by 3ms).\\n4. In summary, a block producer is able to announce a new header 20ms or 21% earlier into the slot (22ms or 43% under Plutus workload).\\n\\nThe metric _\'Slot start to announced\'_ (see in attachments) is cumulative, and demonstrates how far into a slot the block producing node first announces the new header.\\n\\n### Peer propagation\\n\\n1. Under saturation workload only, Block Fetch duration increases by 14ms (or 4%).\\n2. Under saturation, block adoption is slightly _faster_ (by 3ms), while under Plutus workload it\'s slightly _slower_ (by 2ms).\\n\\n### End-to-end propagation\\n\\nThis metric encompasses block diffusion and adoption across specific percentages of the benchmarking cluster, with 0.80 adoption meaning adoption on 80% of all cluster nodes.  \\n\\n1. Under saturation workload, cluster adoption times on `10.5.0` are identical to those on `10.4.1`.\\n2. Under Plutus workload, they show a moderate 3% - 5% _improvement_, with 7% in the 50th percentile.\\n\\n### Conclusion\\n\\n1. We could not detect any regressions or performance risks to the network on `10.5.0`.\\n2. CPU usage is clearly reduced.\\n3. The forging loop executes faster, new header announcements happen earlier.\\n4. Diffusion / adoption metrics exhibit a small overall improvement and indicate `10.5.0` will deliver network performance at least comparable to `10.4.1`.\\n5. All improvements listed above hinge on the [ledger metrics] feature and will materialize only when using the [new tracing system]. Using the legacy system, `10.5.0` performance is expected to be almost identical to `10.4.1`.\\n\\n## Attachments\\n\\nFull comparison for _value-only workload_, PDF downloadable [here](../static/pdf/benchmarking/release-10.5.0.value-only.pdf).\\n\\nFull comparison for _Plutus workload_, PDF downloadable [here](../static/pdf/benchmarking/release-10.5.0.plutus.pdf).  \\n\\nNB. The benchmarks for `10.5.0` extend to a potential `10.5.1` tag, as that won\'t include any changes with a performance impact; thus, measurements performed on `10.5.0` remain valid.\\n\\n\\n[new tracing system]: https://developers.cardano.org/docs/get-started/cardano-node/new-tracing-system/new-tracing-system\\n[ledger metrics]: https://github.com/IntersectMBO/cardano-node/pull/6180"},{"id":"2025-05-performance-10.4.1","metadata":{"permalink":"/reports/2025-05-performance-10.4.1","editUrl":"https://github.com/intersectmbo/cardano-updates/tree/main/reports/2025-05-performance-10.4.1.md","source":"@site/reports/2025-05-performance-10.4.1.md","title":"Benchmarking -- Node 10.4.1","description":"Setup","date":"2025-05-05T15:29:39.000Z","formattedDate":"May 5, 2025","tags":[{"label":"benchmarking-reports","permalink":"/reports/tags/benchmarking-reports"}],"readingTime":3.05,"hasTruncateMarker":false,"authors":[{"name":"Michael Karg","title":"Performance and Tracing Team Lead","url":"https://github.com/mgmeier","imageURL":"https://github.com/mgmeier.png","key":"mgmeier"}],"frontMatter":{"title":"Benchmarking -- Node 10.4.1","slug":"2025-05-performance-10.4.1","authors":"mgmeier","tags":["benchmarking-reports"],"hide_table_of_contents":false},"prevItem":{"title":"Benchmarking -- Node 10.5.0","permalink":"/reports/2025-07-performance-10.5.0"},"nextItem":{"title":"Benchmarking -- Node 10.3.1","permalink":"/reports/2025-04-performance-10.3.1"}},"content":"## Setup\\n\\nAs part of the release benchmarking cycle, we\'re comparing benchmarking runs for 2 different versions of `cardano-node`:\\n* `10.3.1` - baseline from the previous Node release\\n* `10.4.1` - the current release\\n\\nFor this benchmark, we\'re gathering various metrics under 2 different workloads:\\n1. _value-only_: Each transaction consumes 2 inputs and creates 2 outputs, changing the UTxO set. This workload produces full blocks (> 80kB) exclusively.\\n2. _Plutus_: Each transaction contains a Plutus script exhausting the per-tx execution budget. This workload produces small blocks (< 3kB) exclusively.\\n\\nBenchmarking is performed on a cluster of 52 block producing nodes spread across 3 different AWS regions, interconnected using a static, restricted topology. All runs\\nwere performed in the Conway era.  \\n\\n`10.4.1` features the UTxO-HD in-memory backing store `V2InMemory` of `LedgerDB`, which replaces the in-memory representation of UTxO entries in `10.3` and prior.\\n\\n## Observations\\n\\nThese benchmarks are about evaluating specific corner cases in a constrained environment that allows for reliable reproduction of results; they\'re not trying to directly recreate the operational conditions on Mainnet.  \\n\\n### Resource Usage\\n\\n1. On `10.4.0` under value workload, Heap size increases slightly by 2%, and 5% under Plutus workload. This corresponds to using ~170MiB-390MiB additional RAM.\\n2. Allocation rate and GC impact are virtually unchanged.\\n3. Process CPU usage improves slightly by 2% regardless of workload type.\\n4. CPU 85% spans are slightly (~0.37 slots) _longer_ under value workload, and slightly _shorter_ (~0.33) under Plutus workload.\\n\\nCaveat: Individual metrics can\'t be evaluated in isolate; the resource usage profile as a whole provides insight into the system\'s performance and responsiveness.\\n\\n### Forging Loop\\n\\n1. We can observe a clear improvement in Mempool snapshotting by 9ms or 16% (2ms or 8% under Plutus workload).\\n2. Self-Adoption time improves by 4ms or 5% (and remains virtually unchanged under Plutus workload).\\n3. Hence a block producer is able to announce a new header 10ms or 9% earlier into the slot (1ms or 2% under Plutus workload).\\n\\nThe metric _\'Slot start to announced\'_ (see in attachments) is cumulative, and demonstrates how far into a slot the block producing node first announces the new header.\\n\\n### Peer propagation\\n\\n1. Under value workload, Fetch duration and Fetched to Sending improve slightly by 3ms (1%) and 2ms (4%).\\n2. Under Plutus workload, Fetched to Sending has a slightly longer delay - 2ms (or 5%).\\n\\n### End-to-end propagation\\n\\nThis metric encompasses block diffusion and adoption across specific percentages of the benchmarking cluster, with 0.80 adoption meaning adoption on 80% of all cluster nodes.  \\n\\n1. Under value workload, cluster adoption times exhibit a small 1% - 3% _improvement_ across all percentiles.\\n2. Under Plutus workload, they show a small 1% - 2% _increase_ across all percentiles (except the 80th).\\n\\n### Conclusion\\n\\n1. We could not detect any regressions or performance risks to the network on `10.4.1`.\\n2. There is a small and reasonable price to pay in RAM usage for adding the `LedgerDB` abstraction and thus enable exchangeable backing store implementations.\\n3. On the other hand, CPU usage is reduced slightly by use of the in-memory backing store.\\n4. `10.4.1` is beneficial in all cases for block production metrics; specifically, block producers will be able to announce new headers earlier into the slot.\\n5. Network diffusion and adoption metrics vary only slightly and indicate `10.4.1` will deliver network performance comparable to `10.3.1`.\\n\\n## Attachments\\n\\nFull comparison for _value-only workload_, PDF downloadable [here](../static/pdf/benchmarking/release-10.4.1.value-only.pdf).\\n\\nFull comparison for _Plutus workload_, PDF downloadable [here](../static/pdf/benchmarking/release-10.4.1.plutus.pdf).  \\n\\nNB. The benchmarks for `10.4.1` were performed on tag `10.4.0`. The patch version bump did not include changes relevant to performance; thus, measurements performed on `10.4.0` remain valid. The same holds for `10.3.1` and `10.3.0`."},{"id":"2025-04-performance-10.3.1","metadata":{"permalink":"/reports/2025-04-performance-10.3.1","editUrl":"https://github.com/intersectmbo/cardano-updates/tree/main/reports/2025-04-performance-10.3.1.md","source":"@site/reports/2025-04-performance-10.3.1.md","title":"Benchmarking -- Node 10.3.1","description":"Setup","date":"2025-04-22T13:54:50.000Z","formattedDate":"April 22, 2025","tags":[{"label":"benchmarking-reports","permalink":"/reports/tags/benchmarking-reports"}],"readingTime":4.14,"hasTruncateMarker":false,"authors":[{"name":"Michael Karg","title":"Performance and Tracing Team Lead","url":"https://github.com/mgmeier","imageURL":"https://github.com/mgmeier.png","key":"mgmeier"}],"frontMatter":{"title":"Benchmarking -- Node 10.3.1","slug":"2025-04-performance-10.3.1","authors":"mgmeier","tags":["benchmarking-reports"],"hide_table_of_contents":false},"prevItem":{"title":"Benchmarking -- Node 10.4.1","permalink":"/reports/2025-05-performance-10.4.1"},"nextItem":{"title":"Memory Budget Scaling -- 10.2","permalink":"/reports/2025-03-execbudget-memory-10.2"}},"content":"## Setup\\n\\nAs part of the release benchmarking cycle, we\'re comparing benchmarking runs for 3 different versions of `cardano-node`:\\n* `10.2` - baseline from the previous release (bulit with GHC8.10.7)\\n* `10.3.0-ghc8107` - the current release built with GHC8.10.7\\n* `10.3.0-ghc965` - the current release built with GHC9.6.5\\n\\nFor this benchmark, we\'re gathering various metrics under 2 different workloads:\\n1. _value-only_: Each transaction consumes 2 inputs and creates 2 outputs, changing the UTxO set. This workload produces full blocks (> 80kB) exclusively.\\n2. _Plutus_: Each transaction contains a Plutus script exhausting the per-tx execution budget. This workload produces small blocks (< 3kB) exclusively.\\n\\nBenchmarking is performed on a cluster of 52 block producing nodes spread across 3 different AWS regions, interconnected using a static, restricted topology. All runs\\nwere performed in the Conway era.  \\n\\n`10.3.1` supports two compiler versions, which will be taken into account when comparing performance of different builds of that release.\\n\\n## Observations\\n\\nThese benchmarks are about evaluating specific corner cases in a constrained environment that allows for reliable reproduction of results; they\'re not trying to directly recreate the operational conditions on Mainnet.  \\n\\n### Resource Usage\\n\\n1. `10.3.1` exhibits a clear reduction in Process CPU usage, more prominent under _value workload_:\\n    * value workload: 10% with GHC8, and 24% with GHC9.\\n    * Plutus workload: 4% GHC8, and 6% with GHC9.\\n2. There also is a reduction in RAM usage, more prominent under _Plutus workload_:\\n    * value workload: 1% or ~54MiB with GHC8, and 6% or ~574MiB with GHC9.\\n    * Plutus workload: 14% or ~1.2GiB with GHC9 only.\\n3. Minor GCs and Allocation rate both drop on `10.3.1`, more significantly under _value workload_:\\n    * value workload: 11% each with GHC8, and 24% each with GHC9.\\n    * Plutus workload: 3% and 1% with GHC8; 5% and 4% with GHC9. \\n4. Under value workload, CPU 85% spans _increase_ by 45% with GHC8, but only by 14% with GHC9.\\n5. Under Plutus workload, those spans _decrease_ by 5% with GHC8; even by 19% with GHC9.\\n\\nCaveat: Individual metrics can\'t be evaluated in isolate; the resource usage profile as a whole provides insight into the system\'s performance and responsiveness.\\n\\n### Forging Loop\\n\\n1. Under value workload, several block production metrics improve clearly on `10.3.1`, most prominently Mempool Snapshotting.\\n2. With GHC8, the improvement is 23%, with further significant improvements in Adoption time (11%) and Ledger ticking (10%).\\n3. With GHC9, the improvement is 27%, with further significant improvements in Adoption time (10%) and Ledger ticking (17%).\\n4. Under value workload, this enables a block producer to announce a header earlier into the slot, namely by 23ms (GHC8) and by 28ms (GHC9).\\n5. Under Plutus workload, Adoption time _increases_ by 3ms (6%) with GHC8, but _decreases_ by 8ms (15%) with GHC9.\\n6. Furthermore, there are no significant changes to the header announcement timing.\\n\\nThe metric _\'Slot start to announced\'_ (see in attachments) is cumulative, and demonstrates how far into a slot the block producing node first announces the new header.\\n\\n### Peer propagation\\n\\n1. Under value-only workload only, we observe an increase in Block Fetch duration: 7ms (2%) with GHC8, and 23ms (7%) with GHC9.\\n2. Block adoption times on the peers improve clearly: 11ms (12%) with GHC8, and 12ms (14%) with GHC9.\\n3. Under Plutus workload, however, similarly to the block producer, adoption times _increase_ by 3ms (6%) with GHC8, but _decrease_ by 7ms (13%) with GHC9.\\n\\n### End-to-end propagation\\n\\nThis metric encompasses block diffusion and adoption across specific percentages of the benchmarking cluster, with 0.80 adoption meaning adoption on 80% of all cluster nodes.  \\n\\n1. Under value workload, cluster adoption times on `10.3.1` are largely unchanged.\\n2. With GHC8, there are 5% and 3% improvements in the 50th and 100th centiles; with GHC9, there\'s a small 3% improvement in the 50th centile.\\n3. Under Plutus workload, with GHC8, there\'s a moderate 6% _increase_ in cluster adoption times in the 100th centile.\\n4. With GHC9, however, there\'s a small 2% _improvement_ in all but the 100th centile.\\n\\n### Conclusion\\n\\n1. For `10.3.1` we could not detect any performance risks or regressions.\\n2. Improving resource usage was a stated goal for the `10.3` release; this could be confirmed via measurements for CPU and RAM usage as well as CPU spikes.\\n3. `10.3.1` achieves network performance comparable to `10.2.1` using clearly less system resources - for both compiler versions.\\n4. Several key metrics improve on `10.3.1`: Block producers announce a new header sooner into the slot; we observe lower adoption times (GHC9 only).\\n5. The GHC9.6.5 build has demonstrable performance advantages over the GHC8.10.7 build; especially the Plutus interpreter seems to gain considerably from using GHC9. For those reasons we now recommend *GHC9.6.x* for production builds.\\n\\n\\n## Attachments\\n\\nFull report for _value-only workload_, PDF downloadable [here](../static/pdf/benchmarking/release-10.3.1.value-only.pdf).\\n\\nFull report for _Plutus workload_, PDF downloadable [here](../static/pdf/benchmarking/release-10.3.1.plutus.pdf).  \\n\\nNB. The benchmarks for `10.3.1` were performed on tag `10.3.0`. The patch version bump did not include changes relevant to performance; thus, measurements performed on `10.3.0` remain valid."},{"id":"2025-03-execbudget-memory-10.2","metadata":{"permalink":"/reports/2025-03-execbudget-memory-10.2","editUrl":"https://github.com/intersectmbo/cardano-updates/tree/main/reports/2025-03-execbudget-memory-10.2.md","source":"@site/reports/2025-03-execbudget-memory-10.2.md","title":"Memory Budget Scaling -- 10.2","description":"Setup","date":"2025-04-01T09:50:10.000Z","formattedDate":"April 1, 2025","tags":[{"label":"benchmarking-reports","permalink":"/reports/tags/benchmarking-reports"}],"readingTime":2.645,"hasTruncateMarker":false,"authors":[{"name":"Michael Karg","title":"Performance and Tracing Team Lead","url":"https://github.com/mgmeier","imageURL":"https://github.com/mgmeier.png","key":"mgmeier"}],"frontMatter":{"title":"Memory Budget Scaling -- 10.2","slug":"2025-03-execbudget-memory-10.2","authors":"mgmeier","tags":["benchmarking-reports"],"hide_table_of_contents":false},"prevItem":{"title":"Benchmarking -- Node 10.3.1","permalink":"/reports/2025-04-performance-10.3.1"},"nextItem":{"title":"Memory Budget Scaling -- 10.3","permalink":"/reports/2025-05-execbudget-memory-10.3"}},"content":"## Setup\\n\\nThis report compares benchmarking runs for 3 different settings of the Plutus memory execution budget:\\n* `loop-memx1` - current mainnet memory execution budget\\n* `loop-memx1.5` - 1.5 x current mainnet memory execution budget\\n* `loop-memx2` - 2 x current mainnet memory execution budget\\n\\nFor this comparison, we gather various metrics under the _Plutus_ workload used in release benchmarks: Each block produced during the benchmark contains\\n4 identical script transactions calibrated to fully exhaust the memory execution budget. Thus, script execution is constrained by the memory budget limit\\nevery case. The workload produces small blocks (< 3kB) exclusively.  \\n\\nBenchmarking is performed on a cluster of 52 block producing nodes spread across 3 different AWS regions, interconnected using a static, restricted topology. Node\\nversion 10.2 was used, built with GHC8.10.7.\\n\\n## Observations\\n\\n### Resource Usage\\n\\n1. Scaling the memory budget impacts Allocation Rate and Minor GCs. 1.5 x the budget results in rises of 5% and 6% respecetively; for doubling the budget the corresponding rises are 10% and 11%.\\n2. Those increases seem to correlate linearly with raising mem budget.\\n3. The effect on CPU usage is almost negligible: a 1% (or 3%, for doubling the budget) increase of Process CPU.\\n4. The Node process RAM footprint is unaffected.\\n\\nCaveat: Individual metrics can\'t be evaluated in isolate; the resource usage profile as a whole provides insight into the system\'s performance and responsiveness.\\n\\n### Forging Loop\\n\\n1. Scaling the memory budget has significant impact on block adoption time only.\\n2. Scaling by factor 1.5 leads to a 14ms (or 25%) increase, whereas factor 2 leads to 28ms (49%).\\n\\n### Peer propagation\\n\\n1. Same as on the block producer, scaling the memory budget has significant impact on block adoption times only.\\n2. Scaling by factor 1.5 leads to a 15ms (or 26%) increase, whereas factor 2 leads to 28ms (48%).\\n   \\n### End-to-end propagation\\n\\nThis metric encompasses block diffusion and adoption across specific percentages of the benchmarking cluster, with 0.80 adoption meaning adoption on 80% of all cluster nodes.  \\n\\n1. 1.5 x the memory budget results in a slight increase of 19ms - 22ms in cluster adoption times (4% - 5%).\\n2. 2 x the memory budget results in a moderate 27ms - 34ms increase (5% - 7%, with 9% in the 50th centile).\\n\\n### Conclusion\\n\\nThese measurements outline the headroom for raising the memory budget, along with the expected performance impact:\\n1. Block adoption time is the only metric that\'s affected significantly, increasing both on the forger and the peers by the same extent.\\n2. These increases seem to correspond linearly with the raising the memory budget. This gives excellent predictability of performance impact.\\n3. Expectedly, more allocations happen; we can observe the same linear correspondence here as well.\\n4. It has to be pointed out that block diffusion is only slightly affected by changing the execution budget: Due to pipelining, announcing and (re-)sending a block precedes adoption in most cases.\\n5. As such, regarding absolute cluster adoption times, measurements taken with either budget adjustment do not exhibit performance risks to the network. They do illustrate, however, the performance cost of those budget adjustments.\\n\\n## Attachment\\n\\nFull report PDF downloadable [here](../static/pdf/benchmarking/execbudget-10.2-mem_scaling.pdf)."},{"id":"2025-05-execbudget-memory-10.3","metadata":{"permalink":"/reports/2025-05-execbudget-memory-10.3","editUrl":"https://github.com/intersectmbo/cardano-updates/tree/main/reports/2025-05-execbudget-memory-10.3.md","source":"@site/reports/2025-05-execbudget-memory-10.3.md","title":"Memory Budget Scaling -- 10.3","description":"Setup","date":"2025-04-01T09:50:10.000Z","formattedDate":"April 1, 2025","tags":[{"label":"benchmarking-reports","permalink":"/reports/tags/benchmarking-reports"}],"readingTime":3.58,"hasTruncateMarker":false,"authors":[{"name":"Michael Karg","title":"Performance and Tracing Team Lead","url":"https://github.com/mgmeier","imageURL":"https://github.com/mgmeier.png","key":"mgmeier"}],"frontMatter":{"title":"Memory Budget Scaling -- 10.3","slug":"2025-05-execbudget-memory-10.3","authors":"mgmeier","tags":["benchmarking-reports"],"hide_table_of_contents":false},"prevItem":{"title":"Memory Budget Scaling -- 10.2","permalink":"/reports/2025-03-execbudget-memory-10.2"},"nextItem":{"title":"Benchmarking -- UTxO-HD on 10.2","permalink":"/reports/2025-02-performance-utxohd-10.2"}},"content":"## Setup\\n\\nThis report compares benchmarking runs for 3 different settings of the Plutus memory execution budget:\\n* `10.3-ghc965` - current mainnet memory execution budget\\n* `loop-memx1.5` - 1.5 x current mainnet memory execution budget\\n* `loop-memx2` - 2 x current mainnet memory execution budget\\n\\nFor this comparison, we gather various metrics under the _Plutus_ workload used in release benchmarks: Each block produced during the benchmark contains\\n4 identical script transactions calibrated to fully exhaust the memory execution budget. Thus, script execution is constrained by the memory budget limit\\nevery case. The workload produces small blocks (< 3kB) exclusively. \\n\\nBenchmarking is performed on a cluster of 52 block producing nodes spread across 3 different AWS regions, interconnected using a static, restricted topology. Node\\nversion 10.3 was used, built with GHC9.6.5. This is a re-run of the scaling benchmarks performed on Node version 10.2 / GHC8.10 to document impact of performance improvements. Those results\\nwere published here on [Cardano Updates].\\n\\n## Observations\\n\\n### Resource Usage\\n\\n1. Scaling the memory budget impacts Allocation Rate and Minor GCs. 1.5 x the budget results in rises of 5% each; for doubling the budget the corresponding rises are 8% and 9%.\\n2. Those increases seem to correlate linearly with raising mem budget.\\n3. The effects on CPU usage and RAM footprint are negligible for both scaling factors.\\n\\nCaveat: Individual metrics can\'t be evaluated in isolate; the resource usage profile as a whole provides insight into the system\'s performance and responsiveness.\\n\\n### Forging Loop\\n\\n1. Scaling the memory budget has significant impact on block adoption time only.\\n2. Scaling by factor 1.5 leads to a 10ms (or 24%) increase, whereas factor 2 leads to 21ms (50%).\\n\\n### Peer propagation\\n\\n1. Same as on the block producer, scaling the memory budget has significant impact on block adoption times only.\\n2. Scaling by factor 1.5 leads to a 11ms (or 24%) increase, whereas factor 2 leads to 19ms (42%).\\n   \\n### End-to-end propagation\\n\\nThis metric encompasses block diffusion and adoption across specific percentages of the benchmarking cluster, with 0.80 adoption meaning adoption on 80% of all cluster nodes.  \\n\\n1. 1.5 x the memory budget results in a slight increase of  9ms - 31ms in cluster adoption times (3% - 6%).\\n2. 2 x the memory budget results in a moderate 17ms - 35ms increase (5% - 7%).\\n\\n### Conclusion\\n\\nThese measurements outline the headroom for raising the memory budget, along with the expected performance impact:\\n1. Block adoption time is the only metric that\'s affected significantly, increasing both on the forger and the peers by the same extent.\\n2. These increases seem to correspond linearly with the raising the memory budget. This gives excellent predictability of performance impact.\\n3. Expectedly, more allocations happen; we can observe the same linear correspondence here as well.\\n4. It has to be pointed out that block diffusion is only slightly affected by changing the execution budget: Due to pipelining, announcing and (re-)sending a block precedes adoption in most cases.\\n5. As such, regarding absolute cluster adoption times, measurements taken with either budget adjustment do not exhibit performance risks to the network. They do illustrate, however, the performance cost of those budget adjustments.\\n\\nThese scaling benchmarks are complementary to those performed on Node 10.2; in comparison with those, we can additionally conclude:\\n1. The conclusions from measurements for each scaling run set are identical.\\n2. While the relative increases in adoption time for both Node builds are quite similar, the absolute increases are 22% - 32% _smaller_ (i.e., adoption happens more efficiently) for 10.3 / GHC9.6.\\n3. The same rationale applies to end-to-end propagation metrics: Absolute values document faster cluster adoption for 10.3 / GHC9.6. \\n4. Incidentally, the absolute values for scaling factor 1 on 10.2 are close to those for scaling factor 2 on 10.3 except for the tail end (i.e. 95th percentile and above).\\n5. This reflects the performance improvements that were a stated goal for the 10.3 release - and suggests the performance cost of memory budget increases has become slightly _smaller_ in absolute terms.\\n\\nAs adoption times are not only impacted by Plutus execution alone, we still advocate for a conservative and/or multi-stage raise; future backpedaling on budget limits could cause issues for scripts already deployed.\\n\\n## Attachment\\n\\nFull report PDF downloadable [here](../static/pdf/benchmarking/execbudget-10.3-mem_scaling.pdf).\\n\\n[Cardano Updates]: https://updates.cardano.intersectmbo.org/reports/2025-03-execbudget-memory-10.2"},{"id":"2025-02-performance-utxohd-10.2","metadata":{"permalink":"/reports/2025-02-performance-utxohd-10.2","editUrl":"https://github.com/intersectmbo/cardano-updates/tree/main/reports/2025-02-performance-utxohd-10.2.md","source":"@site/reports/2025-02-performance-utxohd-10.2.md","title":"Benchmarking -- UTxO-HD on 10.2","description":"Setup","date":"2025-02-21T17:25:57.000Z","formattedDate":"February 21, 2025","tags":[{"label":"benchmarking-reports","permalink":"/reports/tags/benchmarking-reports"}],"readingTime":2.305,"hasTruncateMarker":false,"authors":[{"name":"Michael Karg","title":"Performance and Tracing Team Lead","url":"https://github.com/mgmeier","imageURL":"https://github.com/mgmeier.png","key":"mgmeier"}],"frontMatter":{"title":"Benchmarking -- UTxO-HD on 10.2","slug":"2025-02-performance-utxohd-10.2","authors":"mgmeier","tags":["benchmarking-reports"],"hide_table_of_contents":false},"prevItem":{"title":"Memory Budget Scaling -- 10.3","permalink":"/reports/2025-05-execbudget-memory-10.3"},"nextItem":{"title":"Benchmarking -- Node 10.2.1","permalink":"/reports/2025-02-performance-10.2.1"}},"content":"## Setup\\n\\nThis report compares benchmarking runs for 2 different flavours of `cardano-node`:\\n* `10.2-regular` - regular Node performance baseline from the `10.2.x` release benchmarks.\\n* `10.2-utxohd` - the UTxO-HD build of the Node based on that same version.\\n\\nFor this benchmark, we\'re gathering various metrics under the _value-only_ workload used in release benchmarks: Each transaction consumes 2 inputs and creates 2 outputs, \\nchanging the UTxO set. This workload produces full blocks (> 80kB) exclusively. Moreover, it\'s the workload that produces most stress on the UTxO set. Thus, it\'s the most meaningful\\nworkload when it comes to benchmarking UTxO-HD.  \\n\\nWe target the _in-memory backing store_ of UTxO-HD - LedgerDB V2 in this case. The on-disk backend is not used. \\n\\nBenchmarking is performed on a cluster of 52 block producing nodes spread across 3 different AWS regions, interconnected using a static, restricted topology.\\n\\n## Observations\\n\\n### Resource Usage\\n\\n1. With UTxO-HD\'s in-memory backend, the memory footprint increases slightly by 3%.\\n2. Process CPU usage is moderately reduced by 9% with UTxO-HD.\\n3. Additionally, CPU 85% spans decrease in duration by 24% (~1.1 slots).\\n\\nCaveat: Individual metrics can\'t be evaluated in isolate; the resource usage profile as a whole provides insight into the system\'s performance and responsiveness.\\n\\n### Forging Loop\\n\\n1. Block context acquisition improves by 3ms (or 11%), while Ledger ticking takes 3ms (or 10%) longer.\\n2. Creating a mempool snapshot is significantly faster - by 16ms (or 21%).\\n3. As a result, a UTxO-HD block producing node is able to announce a new header 17ms (or 12%) earlier into a slot.\\n4. Additionally, adoption time on the forger is slightly improved - by 4ms (or 5%).\\n\\n### Peer propagation\\n\\n1. Block fetch duration increases moderately by 13ms or 4%.\\n2. Adoption times on the peers improve very slightly - by 2ms or 2%.\\n\\n### End-to-end propagation\\n\\nThis metric encompasses block diffusion and adoption across specific percentages of the benchmarking cluster, with 0.80 adoption meaning adoption on 80% of all cluster nodes.  \\n\\n1. There is no significant difference in cluster adoption times between regular and UTxO-HD node.\\n\\n### Conclusion\\n\\nRegarding the UTxO-HD build using the in-memory LedgerDB V2 backend, we can conclude that:\\n1. it is lighter on CPU usage compared to the regular node, albeit requiring just slightly more RAM.\\n2. it poses no performance risk to block producers; on the contrary, the changes in forging loop metrics seem favourable compared to the regular node.  \\n3. network performance would be expeceted to be on par with the regular node.\\n4. even under stress, there is no measurable performance regression compared to the regular node.\\n5. as a consequence of the above, performance-wise, it\'s a viable replacement for the regular in-memory solution.\\n\\n## Attachment\\n\\nFull report for _value-only workload_, PDF downloadable [here](../static/pdf/benchmarking/utxohd-10.2.value-only.pdf)."},{"id":"2025-02-performance-10.2.1","metadata":{"permalink":"/reports/2025-02-performance-10.2.1","editUrl":"https://github.com/intersectmbo/cardano-updates/tree/main/reports/2025-02-performance-10.2.1.md","source":"@site/reports/2025-02-performance-10.2.1.md","title":"Benchmarking -- Node 10.2.1","description":"Setup","date":"2025-02-21T13:39:30.000Z","formattedDate":"February 21, 2025","tags":[{"label":"benchmarking-reports","permalink":"/reports/tags/benchmarking-reports"}],"readingTime":2.67,"hasTruncateMarker":false,"authors":[{"name":"Michael Karg","title":"Performance and Tracing Team Lead","url":"https://github.com/mgmeier","imageURL":"https://github.com/mgmeier.png","key":"mgmeier"}],"frontMatter":{"title":"Benchmarking -- Node 10.2.1","slug":"2025-02-performance-10.2.1","authors":"mgmeier","tags":["benchmarking-reports"],"hide_table_of_contents":false},"prevItem":{"title":"Benchmarking -- UTxO-HD on 10.2","permalink":"/reports/2025-02-performance-utxohd-10.2"},"nextItem":{"title":"Benchmarking -- Node 10.1.4","permalink":"/reports/2025-01-performance-10.1.4"}},"content":"## Setup\\n\\nAs part of the release benchmarking cycle, we\'re comparing benchmarking runs for 2 different versions of `cardano-node`:\\n* `10.1.4` - baseline from a previous mainnet release\\n* `10.2.1` - the current release\\n\\nFor this benchmark, we\'re gathering various metrics under 2 different workloads:\\n1. _value-only_: Each transaction consumes 2 inputs and creates 2 outputs, changing the UTxO set. This workload produces full blocks (> 80kB) exclusively.\\n2. _Plutus_: Each transaction contains a Plutus script exhausting the per-tx execution budget. This workload produces small blocks (< 3kB) exclusively.\\n\\nBenchmarking is performed on a cluster of 52 block producing nodes spread across 3 different AWS regions, interconnected using a static, restricted topology. All runs\\nwere performed in the Conway era.\\n\\n## Observations\\n\\nThese benchmarks are about evaluating specific corner cases in a constrained environment that allows for reliable reproduction of results; they\'re not trying to directly recreate the operational conditions on Mainnet.  \\n\\n### Resource Usage\\n\\n1. CPU usage increases moderately by 12% under value, and very slightly by 2% under Plutus workload.\\n2. CPU 85% spans increase by 14% (~0.6 slots) under value workload, but decrease by 6% (~0.8 slots) under Plutus workload.\\n3. Only under value workload, we observe a slight increase in Allocation rate and Minor GCs of 9% and 8%\\n\\nCaveat: Individual metrics can\'t be evaluated in isolate; the resource usage profile as a whole provides insight into the system\'s performance and responsiveness.\\n\\n### Forging Loop\\n\\n1. Adoption time on the forger improves by 3ms (or 4%) - and 5ms (or 9%) under Plutus workload.\\n2. Block context acquisition takes 3ms (or 12%) longer under value workload.\\n3. Under Plutus workload only, ledger ticking improves by 3ms (or 12%).\\n\\nThe metric _\'Slot start to announced\'_ (see in attachments) is cumulative, and demonstrates how far into a slot the block producing node first announces the new header.\\n\\n### Peer propagation\\n\\n1. Block fetch duration improves clearly by 16ms (or 4%) under value-only workload.\\n2. Under Plutus workload, we can measure an improvement by 4ms (or 7%) for adoption times on the peers.\\n\\n### End-to-end propagation\\n\\nThis metric encompasses block diffusion and adoption across specific percentages of the benchmarking cluster, with 0.80 adoption meaning adoption on 80% of all cluster nodes.  \\n\\nAs a result of the above, on `10.2.1` exhibits:\\n1. a slight 3% improvement in cluster adoption times in the 80th centile and above under value workload.\\n2. a near-jitter 1% - 3% improvement in cluster adoption times under Plutus workload.\\n\\n### Conclusion\\n\\n1. We could not detect any significant regressions, or performance risks, on `10.2.1`.\\n2. `10.2.1` comes with slightly increased CPU usage, and no changes to RAM footprint.\\n3. Diffusion metrics very slightly improve - mainly due to block fetch being more efficient for full blocks, and adoption for blocks exclusively containing Plutus transactions.\\n4. This points to network performance of `10.2.1` being on par with or very slightly better than `10.1.4`.\\n\\n## Attachments\\n\\nFull report for _value-only workload_, PDF downloadable [here](../static/pdf/benchmarking/release-10.2.1.value-only.pdf).\\n\\nFull report for _Plutus workload_, PDF downloadable [here](../static/pdf/benchmarking/release-10.2.1.plutus.pdf).  \\n\\nNB. The benchmarks for `10.2.1` were performed on tag `10.2.0`. The patch version bump did not include changes relevant to performance; thus, measurements and observations performed on `10.2.0` remain valid."},{"id":"2025-01-performance-10.1.4","metadata":{"permalink":"/reports/2025-01-performance-10.1.4","editUrl":"https://github.com/intersectmbo/cardano-updates/tree/main/reports/2025-01-performance-10.1.4.md","source":"@site/reports/2025-01-performance-10.1.4.md","title":"Benchmarking -- Node 10.1.4","description":"Setup","date":"2025-01-10T12:16:13.000Z","formattedDate":"January 10, 2025","tags":[{"label":"benchmarking-reports","permalink":"/reports/tags/benchmarking-reports"}],"readingTime":2.605,"hasTruncateMarker":false,"authors":[{"name":"Michael Karg","title":"Performance and Tracing Team Lead","url":"https://github.com/mgmeier","imageURL":"https://github.com/mgmeier.png","key":"mgmeier"}],"frontMatter":{"title":"Benchmarking -- Node 10.1.4","slug":"2025-01-performance-10.1.4","authors":"mgmeier","tags":["benchmarking-reports"],"hide_table_of_contents":false},"prevItem":{"title":"Benchmarking -- Node 10.2.1","permalink":"/reports/2025-02-performance-10.2.1"},"nextItem":{"title":"Benchmarking -- Node 10.1.1","permalink":"/reports/2024-10-performance-10.1.1"}},"content":"## Setup\\n\\nAs part of the release benchmarking cycle, we\'re comparing benchmarking runs for 2 different versions of `cardano-node`:\\n* `10.1.1` - baseline from a previous mainnet release\\n* `10.1.4` - the current mainnet release\\n\\nFor this benchmark, we\'re gathering various metrics under 2 different workloads:\\n1. _value-only_: Each transaction consumes 2 inputs and creates 2 outputs, changing the UTxO set. This workload produces full blocks (> 80kB) exclusively.\\n2. _Plutus_: Each transaction contains a Plutus script exhausting the per-tx execution budget. This workload produces small blocks (< 3kB) exclusively.\\n\\nBenchmarking is performed on a cluster of 52 block producing nodes spread across 3 different AWS regions, interconnected using a static, restricted topology. All runs\\nwere performed in the Conway era.\\n\\n## Observations\\n\\nThese benchmarks are about evaluating specific corner cases in a constrained environment that allows for reliable reproduction of results; they\'re not trying to directly recreate the operational conditions on Mainnet.  \\n\\n### Resource Usage\\n\\n1. CPU 85% spans slightly increase by 6% or ~0.2 slots (26% or ~2.9 slots under Plutus workload).\\n2. We can observe a tiny increase in memory usage by 1-2% (132-160 MiB).\\n\\nCaveat: Individual metrics can\'t be evaluated in isolate; the resource usage profile as a whole provides insight into the system\'s performance and responsiveness.\\n\\n### Forging Loop\\n\\n1. Under value workload, Ledger Ticking and Self Adoption exhibit a very slight increase (2ms each).\\n2. Block Context Acquisition has improved by 2ms.\\n3. Under Plutus workload, there are no significant changes to forger metrics.\\n\\nThe metric _\'Slot start to announced\'_ (see in attachments) is cumulative, and demonstrates how far into a slot the block producing node first announces the new header.\\n\\n### Peer propagation\\n\\n1. There\'s a minor increase of 1% (3ms) in Block Fetch duration under value workload only.\\n2. Under Plutus workload, we can measure a small improvement by 2% for adoption times on the peers.\\n\\n### End-to-end propagation\\n\\nThis metric encompasses block diffusion and adoption across specific percentages of the benchmarking cluster, with 0.80 adoption meaning adoption on 80% of all cluster nodes.  \\n\\nAs a result of the above, on `10.1.4` we can observe:\\n1. a tiny increase in cluster adoption times of 1%-2% in the 80th centile and above under value workload.\\n2. an improvement in cluster adoption times of 3%-4% in the tail end (95th centile and above) under Plutus workload.\\n\\n### Conclusion\\n\\n1. For `10.1.4`, we could not detect any regressions or performance risks.\\n2. All increases or decreases in forger and peer metrics are 3ms and less. This indicates network performance of `10.1.4` will very closely match that of `10.1.1` and subsequent patch releases.\\n3. There\'s no significant change in the resource usage pattern. The increased CPU 85% spans tend to barely manifest when the system is under heavy load (value workload); as such, they pose no cause for concern. \\n\\n## Attachments\\n\\nFull report for _value-only workload_, PDF downloadable [here](../static/pdf/benchmarking/release-10.1.4.value-only.pdf).\\n\\nFull report for _Plutus workload_, PDF downloadable [here](../static/pdf/benchmarking/release-10.1.4.plutus.pdf).  \\n\\nNB. The benchmarks for `10.1.1` were performed on tag `10.0.0-pre`. The minor version bump did not include changes relevant to performance; thus, measurements taken on `10.0.0-pre` remain a valid baseline."},{"id":"2024-10-performance-10.1.1","metadata":{"permalink":"/reports/2024-10-performance-10.1.1","editUrl":"https://github.com/intersectmbo/cardano-updates/tree/main/reports/2024-10-performance-10.1.1.md","source":"@site/reports/2024-10-performance-10.1.1.md","title":"Benchmarking -- Node 10.1.1","description":"Setup","date":"2024-10-31T11:03:27.000Z","formattedDate":"October 31, 2024","tags":[{"label":"benchmarking-reports","permalink":"/reports/tags/benchmarking-reports"}],"readingTime":3.925,"hasTruncateMarker":false,"authors":[{"name":"Michael Karg","title":"Performance and Tracing Team Lead","url":"https://github.com/mgmeier","imageURL":"https://github.com/mgmeier.png","key":"mgmeier"}],"frontMatter":{"title":"Benchmarking -- Node 10.1.1","slug":"2024-10-performance-10.1.1","authors":"mgmeier","tags":["benchmarking-reports"],"hide_table_of_contents":false},"prevItem":{"title":"Benchmarking -- Node 10.1.4","permalink":"/reports/2025-01-performance-10.1.4"},"nextItem":{"title":"Benchmarking -- Node 8.9.0","permalink":"/reports/2024-03-performance-8.9.0"}},"content":"## Setup\\n\\nAs part of the release benchmarking cycle, we\'re comparing benchmarking runs for 2 different versions of `cardano-node`:\\n* `9.2.0` - baseline from a previous mainnet release\\n* `10.1.1` - the current mainnet release\\n\\nFor this benchmark, we\'re gathering various metrics under 3 different workloads:\\n1. _value-only_: Each transaction consumes 2 inputs and creates 2 outputs, changing the UTxO set. This workload produces full blocks (> 80kB) exclusively.\\n2. _Plutus_: Each transaction contains a Plutus script exhausting the per-tx execution budget. This workload produces small blocks (< 3kB) exclusively.\\n3. _value+voting_: On top of above value workload, this one has DReps vote on and ratify governance actions - forcing additional computation for vote tallying and proposal enactment.\\n\\nBenchmarking is performed on a cluster of 52 block producing nodes spread across 3 different AWS regions, interconnected using a static, restricted topology. All runs\\nwere performed in the Conway era.\\n\\n## Observations\\n\\nThese benchmarks are about evaluating specific corner cases in a constrained environment that allows for reliable reproduction of results; they\'re not trying to directly recreate the operational conditions on Mainnet.  \\n\\n### Resource Usage\\n\\n1. `10.1.1` shows an improvement of 4% (8% under Plutus workload) in Process CPU usage.\\n2. Allocation Rate improves by 8% (11% under Plutus workload), while Heap Size remains unchanged.\\n3. CPU 85% spans decrease by 18% (5% under Plutus workload).\\n4. Compared to value-only workload, ongoing voting leads to a slight increase of 5% in Process CPU usage.\\n\\nCaveat: Individual metrics can\'t be evaluated in isolate; the resource usage profile as a whole provides insight into the system\'s performance and responsiveness.\\n\\n### Forging Loop\\n\\n1. Under Plutus workload, `10.1.1` exhibits a formidable speedup of 70ms in the forging loop - due to mempool snapshots being produced much more quickly.\\n2. Under value workload, there are no significant changes to forger metrics.\\n3. With voting added on top of the value workload, we can observe mempool snapshots and adoption time on the block producer rise by 10ms each.\\n\\nThe metric _\'Slot start to announced\'_ (see in attachments) is cumulative, and demonstrates how far into a slot the block producing node first announces the new header.\\n\\n### Peer propagation\\n\\n1. Block Fetch duration increases slightly by 16ms (or 5%) under value workload.\\n2. Under Plutus workload, there are no significant changes to peer-related metrics.\\n3. With the additional voting workload, peer adoption times rise by 12ms on average - confirming the observation for adoption time on the block producer.\\n\\n### End-to-end propagation\\n\\nThis metric encompasses block diffusion and adoption across specific percentages of the benchmarking cluster, with 0.80 adoption meaning adoption on 80% of all cluster nodes.  \\n\\n1. `10.1.1` exhibits a slight increase of 2% - 3% in cluster adoption times under value workload.\\n2. Under Plutus workload however, we observe significant improvement of 18% up to the 50th centile, and 9% - 13% in the 80th centile and above.\\n3. While the former is due to slightly increased Block Fetch duration, the latter is the consequence of much quicker mempool snapshots involving Plutus transactions.\\n4. Submitting the additional voting workload, we can observe a consistent 4% - 6% increase in cluster adoption times across all centiles.\\n\\n### Conclusion\\n\\n* We do not detect any perfomance regression in `10.1.1` compared to `9.2.0`.\\n* To the contrary - `10.1.1` is lighter on the Node process resource usage overall.\\n* Improved forging and diffusion timings can be expected for blocks heavy on Plutus transactions.\\n* Stressing the governance / voting capabalities of the Conway ledger lets us ascertain an (expected) performance cost of voting.\\n* This cost has demonstrated to be reasonable, and to not contain lurking perfomance risks to the system.\\n* It is expected to manifest only during periods of heavy vote tallying / proposal enactment, slightly affecting block adoption times.\\n\\nNB. The same amount of DReps are registered for each workload. However, only under _value+voting_ do they become active by submitting votes. This requires an increased UTxO set size, so it uses\\na baseline seperate from _value-only_, resulting in slightly different absolute values.  \\n\\n## Contact\\n\\nAs for publishing such benchmarking results, we are aware that more context and detail may be needed with regard to specfic metrics or benchmarking methodology. \\n\\nWe are still looking to gather questions, both general and specific, so that we can provide a suitable FAQ and possibly improve presentation in the future.\\n\\n## Attachments\\n\\nFull report for _value-only workload_, PDF downloadable [here](../static/pdf/benchmarking/release-10.1.1.value-only.pdf).\\n\\nFull report for _Plutus workload_, PDF downloadable [here](../static/pdf/benchmarking/release-10.1.1.plutus.pdf).  \\n\\nFull report for _value+voting workload_, PDF downloadable [here](../static/pdf/benchmarking/release-10.1.1.voting.pdf).  \\n\\nNB. The release benchmarks for `10.1.1` were performed on tag `10.0.0-pre`. The minor version bump did not include changes relevant to performance; thus, measurements taken on `10.0.0-pre` remain valid."},{"id":"2024-03-performance-8.9.0","metadata":{"permalink":"/reports/2024-03-performance-8.9.0","editUrl":"https://github.com/intersectmbo/cardano-updates/tree/main/reports/2024-03-performance-8.9.0.md","source":"@site/reports/2024-03-performance-8.9.0.md","title":"Benchmarking -- Node 8.9.0","description":"Setup","date":"2024-03-13T09:34:49.000Z","formattedDate":"March 13, 2024","tags":[{"label":"benchmarking-reports","permalink":"/reports/tags/benchmarking-reports"}],"readingTime":2.43,"hasTruncateMarker":false,"authors":[{"name":"Michael Karg","title":"Performance and Tracing Team Lead","url":"https://github.com/mgmeier","imageURL":"https://github.com/mgmeier.png","key":"mgmeier"}],"frontMatter":{"title":"Benchmarking -- Node 8.9.0","slug":"2024-03-performance-8.9.0","authors":"mgmeier","tags":["benchmarking-reports"],"hide_table_of_contents":false},"prevItem":{"title":"Benchmarking -- Node 10.1.1","permalink":"/reports/2024-10-performance-10.1.1"},"nextItem":{"title":"Benchmarking -- Node 8.9.1","permalink":"/reports/2024-03-performance-8.9.1"}},"content":"## Setup\\n\\nAs part of the release benchmarking cycle, we\'re comparing benchmarking runs for 3 different versions of `cardano-node`:\\n* `8.7.2` - baseline for previous mainnet release\\n* `8.8.0` - an intermediate reference point\\n* `8.9.0` - the next mainnet release\\n\\nFor each version, we\'re gathering various metrics under 2 different workloads:\\n1. _value-only_: Each transaction consumes 2 inputs and creates 2 outputs, changing the UTxO set. This workload produces full blocks (> 80kB) exclusively.\\n2. _Plutus_: Each transaction contains a Plutus script exhausting the per-tx execution budget. This workload produces small blocks (< 3kB) exclusively.\\n\\nBenchmarking is performed on a cluster of 52 block producing nodes spread across 3 different AWS regions, interconnected using a static, restricted topology. All runs\\nwere performed in the Babbage era.\\n\\n\\n## Observations\\n\\nThese benchmarks are about evaluating specific corner cases in a constrained environment that allows for reliable reproduction of results; they\'re not trying to directly recreate the operational conditions on Mainnet.  \\n\\nThe observations stated refer to the direct comparison between the `8.7.2` and `8.9.0` versions.\\n\\n### Resource Usage\\n\\n1. Overall CPU usage exhibits a small to moderate (5% - 8%) increase.\\n2. Memory usage is very slightly decreased by 1%.\\n\\nCaveat: Individual metrics can\'t be evaluated in isolate; the resource usage profile as a whole provides insight into the system\'s performance and responsiveness.\\n\\n\\n### Forging Loop\\n\\n1. For full blocks, Mempool Snapshotting improves by 4% (or 3ms).\\n2. For small blocks, Self Adoption times improve by 8% (or 4ms).\\n3. All other forger metrics do not exhibit significant change.\\n\\nThe metric _\'Slot start to announced\'_ (see in attachments) is cumulative, and demonstrates how far into a slot the block producing node first announces the new header.\\n\\n### Peer propagation\\n\\n1. For full blocks, Block Fetch duration shows a notable improvement by 10ms (or 3%).\\n\\n### End-to-end propagation\\n\\nThis metric encompasses block diffusion and adoption across specific percentages of the benchmarking cluster, with 0.80 adoption meaning adoption on 80% of all cluster nodes.  \\n\\nEnd-to-end propagation times on `8.9.0` exhibit a small improvement by 2% across all centiles for full blocks, whereas they remain largely unchanged for small blocks.\\n\\n\\n### Conclusion\\n\\n* The performance changes observed between `8.9.0` and `8.7.2` are only minor - with `8.9.0` slightly improving on `8.7.2`. Therefore, we\'d expect `8.9.0` Mainnet performance to be akin to `8.7.2`.\\n* We have demonstrated no performance regression has been introduced in `8.9.0`.\\n\\n## Contact\\n\\nAs for publishing such benchmarking results, we are aware that more context and detail may be needed with regard to specfic metrics or benchmarking methodology. \\n\\nWe are still looking to gather questions, both general and specific, so that we can provide a suitable FAQ and possibly improve presentation in the future.\\n\\n## Attachments\\n\\nFull report for _value-only workload_, PDF downloadable [here](../static/pdf/benchmarking/release-8.9.0.value-only.pdf).\\n\\nFull report for _Plutus workload_, PDF downloadable [here](../static/pdf/benchmarking/release-8.9.0.plutus.pdf).\\n\\nNB. Mainnet release `8.7.3` did not include any performance-related changes; measurements taken on `8.7.2` remain valid."},{"id":"2024-03-performance-8.9.1","metadata":{"permalink":"/reports/2024-03-performance-8.9.1","editUrl":"https://github.com/intersectmbo/cardano-updates/tree/main/reports/2024-03-performance-8.9.1.md","source":"@site/reports/2024-03-performance-8.9.1.md","title":"Benchmarking -- Node 8.9.1","description":"Setup","date":"2024-03-13T09:34:49.000Z","formattedDate":"March 13, 2024","tags":[{"label":"benchmarking-reports","permalink":"/reports/tags/benchmarking-reports"}],"readingTime":2.285,"hasTruncateMarker":false,"authors":[{"name":"Michael Karg","title":"Performance and Tracing Team Lead","url":"https://github.com/mgmeier","imageURL":"https://github.com/mgmeier.png","key":"mgmeier"}],"frontMatter":{"title":"Benchmarking -- Node 8.9.1","slug":"2024-03-performance-8.9.1","authors":"mgmeier","tags":["benchmarking-reports"],"hide_table_of_contents":false},"prevItem":{"title":"Benchmarking -- Node 8.9.0","permalink":"/reports/2024-03-performance-8.9.0"},"nextItem":{"title":"Benchmarking -- Node 8.9.3","permalink":"/reports/2024-05-performance-8.9.3"}},"content":"## Setup\\n\\nAs part of the release benchmarking cycle, we\'re comparing benchmarking runs for 2 different versions of `cardano-node`:\\n* `8.9.0` - baseline for previous mainnet release\\n* `8.9.1` - the next mainnet release\\n\\nFor each version, we\'re gathering various metrics under 2 different workloads:\\n1. _value-only_: Each transaction consumes 2 inputs and creates 2 outputs, changing the UTxO set. This workload produces full blocks (> 80kB) exclusively.\\n2. _Plutus_: Each transaction contains a Plutus script exhausting the per-tx execution budget. This workload produces small blocks (< 3kB) exclusively.\\n\\nBenchmarking is performed on a cluster of 52 block producing nodes spread across 3 different AWS regions, interconnected using a static, restricted topology. All runs\\nwere performed in the Babbage era.\\n\\n\\n## Observations\\n\\nThese benchmarks are about evaluating specific corner cases in a constrained environment that allows for reliable reproduction of results; they\'re not trying to directly recreate the operational conditions on Mainnet.  \\n\\n### Resource Usage\\n\\n1. We can observe an overall decrease in CPU usage (2% - 4%); only GC CPU usage under value workload increases by 3%.\\n2. Under value workload only, Allocation rate is very slightly decreased (1%) with no change to Heap Size.\\n\\nCaveat: Individual metrics can\'t be evaluated in isolate; the resource usage profile as a whole provides insight into the system\'s performance and responsiveness.\\n\\n\\n### Forging Loop\\n\\n1. Mempool Snapshot duration increases slightly by 2ms under value workload.\\n2. Self-Adoption time increases by 3ms.\\n3. All other forger metrics do not exhibit significant change.\\n\\nThe metric _\'Slot start to announced\'_ (see in attachments) is cumulative, and demonstrates how far into a slot the block producing node first announces the new header.\\n\\n### Peer propagation\\n\\n1. Under value workload only, Block Fetch duration and Fetched to Sending show a slight increase of 2ms each.\\n\\n### End-to-end propagation\\n\\nThis metric encompasses block diffusion and adoption across specific percentages of the benchmarking cluster, with 0.80 adoption meaning adoption on 80% of all cluster nodes.  \\n\\nEnd-to-end propagation times on `8.9.1` exhibit a small increase by 1% - 2% for full blocks, while remaining virtually unchanged for small blocks.\\n\\n\\n### Conclusion\\n\\n* The performance changes measured between `8.9.1` and `8.9.0` are very minor. Mainnnet performance of `8.9.1` is expected to be akin to `8.9.0`.\\n* We have not observed any performance regression being introduced in `8.9.1`.\\n\\n## Contact\\n\\nAs for publishing such benchmarking results, we are aware that more context and detail may be needed with regard to specfic metrics or benchmarking methodology. \\n\\nWe are still looking to gather questions, both general and specific, so that we can provide a suitable FAQ and possibly improve presentation in the future.\\n\\n## Attachments\\n\\nFull report for _value-only workload_, PDF downloadable [here](../static/pdf/benchmarking/release-8.9.1.value-only.pdf).\\n\\nFull report for _Plutus workload_, PDF downloadable [here](../static/pdf/benchmarking/release-8.9.1.plutus.pdf)."},{"id":"2024-05-performance-8.9.3","metadata":{"permalink":"/reports/2024-05-performance-8.9.3","editUrl":"https://github.com/intersectmbo/cardano-updates/tree/main/reports/2024-05-performance-8.9.3.md","source":"@site/reports/2024-05-performance-8.9.3.md","title":"Benchmarking -- Node 8.9.3","description":"Setup","date":"2024-03-13T09:34:49.000Z","formattedDate":"March 13, 2024","tags":[{"label":"benchmarking-reports","permalink":"/reports/tags/benchmarking-reports"}],"readingTime":2.69,"hasTruncateMarker":false,"authors":[{"name":"Michael Karg","title":"Performance and Tracing Team Lead","url":"https://github.com/mgmeier","imageURL":"https://github.com/mgmeier.png","key":"mgmeier"}],"frontMatter":{"title":"Benchmarking -- Node 8.9.3","slug":"2024-05-performance-8.9.3","authors":"mgmeier","tags":["benchmarking-reports"],"hide_table_of_contents":false},"prevItem":{"title":"Benchmarking -- Node 8.9.1","permalink":"/reports/2024-03-performance-8.9.1"},"nextItem":{"title":"Benchmarking -- Node 8.12.1","permalink":"/reports/2024-06-performance-8.12.1"}},"content":"## Setup\\n\\nAs part of the release benchmarking cycle, we\'re comparing benchmarking runs for 2 different versions of `cardano-node`:\\n* `8.9.1` - baseline from a previous mainnet release\\n* `8.9.3` - the current mainnet release\\n\\nFor each version, we\'re gathering various metrics under 2 different workloads:\\n1. _value-only_: Each transaction consumes 2 inputs and creates 2 outputs, changing the UTxO set. This workload produces full blocks (> 80kB) exclusively.\\n2. _Plutus_: Each transaction contains a Plutus script exhausting the per-tx execution budget. This workload produces small blocks (< 3kB) exclusively.\\n\\nBenchmarking is performed on a cluster of 52 block producing nodes spread across 3 different AWS regions, interconnected using a static, restricted topology. All runs\\nwere performed in the Babbage era.\\n\\n\\n## Observations\\n\\nThese benchmarks are about evaluating specific corner cases in a constrained environment that allows for reliable reproduction of results; they\'re not trying to directly recreate the operational conditions on Mainnet.  \\n\\n### Resource Usage\\n\\n1. Under value workload, CPU usage increases slightly on `8.9.3`: 4% for Process, 3% for Mutator and 8% for GC.\\n2. Additionally, Allocation rate and minor GCs increase slightly by 3% each.\\n3. Under Plutus workload only, the GC live dataset increases by 10% or 318MB.\\n4. CPU 85% spans increase by 14% of slot duration under value workload, whereas they shorten by 5% of slot duration under Plutus workload.\\n\\nCaveat: Individual metrics can\'t be evaluated in isolate; the resource usage profile as a whole provides insight into the system\'s performance and responsiveness.\\n\\n### Forging Loop\\n\\n1. There are no significant changes to metrics related to block forging.\\n\\nThe metric _\'Slot start to announced\'_ (see in attachments) is cumulative, and demonstrates how far into a slot the block producing node first announces the new header.\\n\\n### Peer propagation\\n\\n1. Block Fetch duration improves by 7ms (or 2%) under value workload, and by 4ms (or 3%) under Plutus workload.\\n2. Under Plutus workload, Fetched to sending improves by 2ms (or 5%).\\n\\n### End-to-end propagation\\n\\nThis metric encompasses block diffusion and adoption across specific percentages of the benchmarking cluster, with 0.80 adoption meaning adoption on 80% of all cluster nodes.  \\n\\n1. Under value workload, cluster adoption times exhibit a minor improvement (1%) up to the 80th centile on `8.9.3`.\\n2. Under Plutus workload, we can observe a minor improvement overall (1% - 2%), whilst full adoption is unchanged.\\n\\n\\n### Conclusion\\n\\n* The performance changes measured between `8.9.3` and `8.9.1` are very minor, with `8.9.3` improving slightly over `8.9.1`.\\n* Mainnnet performance of `8.9.3` is expected to be akin to `8.9.1`.\\n* We have not observed any performance regression being introduced in `8.9.3`.\\n\\n## Contact\\n\\nAs for publishing such benchmarking results, we are aware that more context and detail may be needed with regard to specfic metrics or benchmarking methodology. \\n\\nWe are still looking to gather questions, both general and specific, so that we can provide a suitable FAQ and possibly improve presentation in the future.\\n\\n## Attachments\\n\\nFull report for _value-only workload_, PDF downloadable [here](../static/pdf/benchmarking/release-8.9.3.value-only.pdf).\\n\\nFull report for _Plutus workload_, PDF downloadable [here](../static/pdf/benchmarking/release-8.9.3.plutus.pdf).\\n\\nNB. The baseline for `8.9.1` had to be re-established due to changes in the underlying network infrastructure. This means, absolute values may differ from the previous measurements taken from that version."},{"id":"2024-06-performance-8.12.1","metadata":{"permalink":"/reports/2024-06-performance-8.12.1","editUrl":"https://github.com/intersectmbo/cardano-updates/tree/main/reports/2024-06-performance-8.12.1.md","source":"@site/reports/2024-06-performance-8.12.1.md","title":"Benchmarking -- Node 8.12.1","description":"Setup","date":"2024-03-13T09:34:49.000Z","formattedDate":"March 13, 2024","tags":[{"label":"benchmarking-reports","permalink":"/reports/tags/benchmarking-reports"}],"readingTime":2.84,"hasTruncateMarker":false,"authors":[{"name":"Michael Karg","title":"Performance and Tracing Team Lead","url":"https://github.com/mgmeier","imageURL":"https://github.com/mgmeier.png","key":"mgmeier"}],"frontMatter":{"title":"Benchmarking -- Node 8.12.1","slug":"2024-06-performance-8.12.1","authors":"mgmeier","tags":["benchmarking-reports"],"hide_table_of_contents":false},"prevItem":{"title":"Benchmarking -- Node 8.9.3","permalink":"/reports/2024-05-performance-8.9.3"},"nextItem":{"title":"Benchmarking -- Node 9.0.0","permalink":"/reports/2024-07-performance-9.0.0"}},"content":"## Setup\\n\\nAs part of the release benchmarking cycle, we\'re comparing benchmarking runs for 2 different versions of `cardano-node`:\\n* `8.9.3` - baseline from a previous mainnet release\\n* `8.12.1` - the current mainnet release\\n\\nFor each version, we\'re gathering various metrics under 2 different workloads:\\n1. _value-only_: Each transaction consumes 2 inputs and creates 2 outputs, changing the UTxO set. This workload produces full blocks (> 80kB) exclusively.\\n2. _Plutus_: Each transaction contains a Plutus script exhausting the per-tx execution budget. This workload produces small blocks (< 3kB) exclusively.\\n\\nBenchmarking is performed on a cluster of 52 block producing nodes spread across 3 different AWS regions, interconnected using a static, restricted topology. All runs\\nwere performed in the Babbage era.\\n\\n\\n## Observations\\n\\nThese benchmarks are about evaluating specific corner cases in a constrained environment that allows for reliable reproduction of results; they\'re not trying to directly recreate the operational conditions on Mainnet.  \\n\\n### Resource Usage\\n\\n1. Under value workload, CPU usage is improved by 2% - 4%, and by 14% for GCs. Under Plutus workload, CPU usage improves only slightly by 1%.\\n2. Allocation Rate and Minor GCs improve by 5% and 6% - under Plutus workload, there\'s a slight improvement of 1%.\\n3. RAM usage is reduced by 3%; reduction under Plutus workload is even larger - namely 10%.\\n\\nCaveat: Individual metrics can\'t be evaluated in isolate; the resource usage profile as a whole provides insight into the system\'s performance and responsiveness.\\n\\n### Forging Loop\\n\\n1. Mempool snapshotting improves by 5ms or 7% (3ms or 4% under Plutus workload).\\n2. Adoption time on the block producer improves by 4ms or 6% - under value workload only.\\n\\nThe metric _\'Slot start to announced\'_ (see in attachments) is cumulative, and demonstrates how far into a slot the block producing node first announces the new header.\\n\\n### Peer propagation\\n\\n1. Block Fetch duration increases slightly by 6ms or 2% (2ms under Plutus workload).\\n2. Adoption times on the peers improve slightly by 2ms or 3% (1ms under Plutus workload)\\n\\n### End-to-end propagation\\n\\nThis metric encompasses block diffusion and adoption across specific percentages of the benchmarking cluster, with 0.80 adoption meaning adoption on 80% of all cluster nodes.  \\n\\n1. Under value workload / full blocks there are no significant changes to cluster adoption times.\\n2. Under Plutus workload / small blocks we can observe a (near-jitter) improvement of 0% - 2% in cluster adoption times.\\n\\n\\n### Conclusion\\n\\n* The performance changes measured between `8.12.1` and `8.9.3` are most distinct in the resource usage footprint - with `8.12.1` improving over `8.9.3`.\\n* On Mainnnet, `8.12.1` is expected to deliver equal or slightly better performance than `8.9.3` - as well as lowering the Node\'s resource usage somewhat in doing so.\\n* We have not observed any performance regression being introduced in `8.12.1`.\\n\\n## Contact\\n\\nAs for publishing such benchmarking results, we are aware that more context and detail may be needed with regard to specfic metrics or benchmarking methodology. \\n\\nWe are still looking to gather questions, both general and specific, so that we can provide a suitable FAQ and possibly improve presentation in the future.\\n\\n## Attachments\\n\\nFull report for _value-only workload_, PDF downloadable [here](../static/pdf/benchmarking/release-8.12.1.value-only.pdf).\\n\\nFull report for _Plutus workload_, PDF downloadable [here](../static/pdf/benchmarking/release-8.12.1.plutus.pdf).\\n\\nNB. The release benchmarks for `8.12.1` were performed on tag `8.12.0-pre`. The patch version bump did not include changes relevant to performance; thus, measurements taken on `8.12.0-pre` remain valid."},{"id":"2024-07-performance-9.0.0","metadata":{"permalink":"/reports/2024-07-performance-9.0.0","editUrl":"https://github.com/intersectmbo/cardano-updates/tree/main/reports/2024-07-performance-9.0.0.md","source":"@site/reports/2024-07-performance-9.0.0.md","title":"Benchmarking -- Node 9.0.0","description":"Setup","date":"2024-03-13T09:34:49.000Z","formattedDate":"March 13, 2024","tags":[{"label":"benchmarking-reports","permalink":"/reports/tags/benchmarking-reports"}],"readingTime":3.11,"hasTruncateMarker":false,"authors":[{"name":"Michael Karg","title":"Performance and Tracing Team Lead","url":"https://github.com/mgmeier","imageURL":"https://github.com/mgmeier.png","key":"mgmeier"}],"frontMatter":{"title":"Benchmarking -- Node 9.0.0","slug":"2024-07-performance-9.0.0","authors":"mgmeier","tags":["benchmarking-reports"],"hide_table_of_contents":false},"prevItem":{"title":"Benchmarking -- Node 8.12.1","permalink":"/reports/2024-06-performance-8.12.1"},"nextItem":{"title":"Benchmarking -- Node 9.2.0","permalink":"/reports/2024-09-performance-9.2.0"}},"content":"## Setup\\n\\nAs part of the release benchmarking cycle, we\'re comparing benchmarking runs for 2 different versions of `cardano-node`:\\n* `8.12.1` - baseline from a previous mainnet release\\n* `9.0.0` - the current mainnet release\\n\\nFor each version, we\'re gathering various metrics under 2 different workloads:\\n1. _value-only_: Each transaction consumes 2 inputs and creates 2 outputs, changing the UTxO set. This workload produces full blocks (> 80kB) exclusively.\\n2. _Plutus_: Each transaction contains a Plutus script exhausting the per-tx execution budget. This workload produces small blocks (< 3kB) exclusively.\\n\\nBenchmarking is performed on a cluster of 52 block producing nodes spread across 3 different AWS regions, interconnected using a static, restricted topology. All runs\\nwere performed in the Conway era.\\n\\n## Observations\\n\\nThese benchmarks are about evaluating specific corner cases in a constrained environment that allows for reliable reproduction of results; they\'re not trying to directly recreate the operational conditions on Mainnet.  \\n\\n### Resource Usage\\n\\n1. Under value workload Process and Mutator CPU usage are slightly higher on `9.0` - 7% - 8% (4% each under Plutus workload). GC CPU is increased by 11%, but decreases under Putus workload by 3%.\\n2. Only under value workload, Allocation Rate and Minor GCs increase by 5% and the live GC dataset grows by 3%. Heap size is constant.\\n3. CPU 85% spans are 8% shorter (3% under Plutus workload).\\n\\nCaveat: Individual metrics can\'t be evaluated in isolate; the resource usage profile as a whole provides insight into the system\'s performance and responsiveness.\\n\\n### Forging Loop\\n\\n1. Mempool Snapshotting and Self Adoption time on the block producer increase very slightly under value workload - 2ms (or 3%) each.\\n2. Under Plutus workload, however, a decrease in Self Adoption time by 2ms (or 4%) is the only significant change in the forging loop.\\n\\nThe metric _\'Slot start to announced\'_ (see in attachments) is cumulative, and demonstrates how far into a slot the block producing node first announces the new header.\\n\\n### Peer propagation\\n\\n1. Block Fetch duration is 21ms faster (6%) - 7ms or 5% under Plutus workload.\\n2. Fetched to Sending increases slightly by 3ms (7%) - only under value workload.\\n3. Adoption times on the peers increase slightly by 4ms (5%) - under Plutus workload, however, they are 3ms (6%) faster.\\n\\n### End-to-end propagation\\n\\nThis metric encompasses block diffusion and adoption across specific percentages of the benchmarking cluster, with 0.80 adoption meaning adoption on 80% of all cluster nodes.  \\n\\n1. Under value workload / full blocks on `9.0`, we can observe a 4% - 5% improvement of cluster adoption times in the 80th centile and above.\\n2. Under Plutus workload / small blocks, the corresponding improvement is 5% - 6%.\\n3. The main contributing factor is the improvement in Block Fetch duration.\\n\\n\\n### Conclusion\\n\\n* Network performance clearly improves by ~%5 for 80% to full cluster adoption - independent of workload.\\n* RAM usage is unchanged on `9.0`. The slight rise in CPU usage is expected, given improved network performance, and does not pose cause for concern.\\n* We have not observed any performance regression being introduced in `9.0.0.`.\\n\\nNB. These benchmarks were performed in the Conway ledger era. As such, they do not cover the one-time performance cost of transitioning from Babbage and enabling the new features of the Conway ledger.\\n\\n## Contact\\n\\nAs for publishing such benchmarking results, we are aware that more context and detail may be needed with regard to specfic metrics or benchmarking methodology. \\n\\nWe are still looking to gather questions, both general and specific, so that we can provide a suitable FAQ and possibly improve presentation in the future.\\n\\n## Attachments\\n\\nFull report for _value-only workload_, PDF downloadable [here](../static/pdf/benchmarking/release-9.0.0.value-only.pdf).\\n\\nFull report for _Plutus workload_, PDF downloadable [here](../static/pdf/benchmarking/release-9.0.0.plutus.pdf)."},{"id":"2024-09-performance-9.2.0","metadata":{"permalink":"/reports/2024-09-performance-9.2.0","editUrl":"https://github.com/intersectmbo/cardano-updates/tree/main/reports/2024-09-performance-9.2.0.md","source":"@site/reports/2024-09-performance-9.2.0.md","title":"Benchmarking -- Node 9.2.0","description":"Setup","date":"2024-03-13T09:34:49.000Z","formattedDate":"March 13, 2024","tags":[{"label":"benchmarking-reports","permalink":"/reports/tags/benchmarking-reports"}],"readingTime":2.93,"hasTruncateMarker":false,"authors":[{"name":"Michael Karg","title":"Performance and Tracing Team Lead","url":"https://github.com/mgmeier","imageURL":"https://github.com/mgmeier.png","key":"mgmeier"}],"frontMatter":{"title":"Benchmarking -- Node 9.2.0","slug":"2024-09-performance-9.2.0","authors":"mgmeier","tags":["benchmarking-reports"],"hide_table_of_contents":false},"prevItem":{"title":"Benchmarking -- Node 9.0.0","permalink":"/reports/2024-07-performance-9.0.0"},"nextItem":{"title":"Benchmarking -- Node 8.7.2","permalink":"/reports/2023-12-performance-8.7.2"}},"content":"## Setup\\n\\nAs part of the release benchmarking cycle, we\'re comparing benchmarking runs for 2 different versions of `cardano-node`:\\n* `9.1.1` - baseline from a previous mainnet release\\n* `9.2.0` - the current mainnet release\\n\\nFor each version, we\'re gathering various metrics under 2 different workloads:\\n1. _value-only_: Each transaction consumes 2 inputs and creates 2 outputs, changing the UTxO set. This workload produces full blocks (> 80kB) exclusively.\\n2. _Plutus_: Each transaction contains a Plutus script exhausting the per-tx execution budget. This workload produces small blocks (< 3kB) exclusively.\\n\\nBenchmarking is performed on a cluster of 52 block producing nodes spread across 3 different AWS regions, interconnected using a static, restricted topology. All runs\\nwere performed in the Conway era.\\n\\n## Observations\\n\\nThese benchmarks are about evaluating specific corner cases in a constrained environment that allows for reliable reproduction of results; they\'re not trying to directly recreate the operational conditions on Mainnet.  \\n\\n### Resource Usage\\n\\n1. Under value workload, `9.2.0` shows an increase by 7% in Process CPU usage.\\n2. Additionally, Allocation Rate and Minor GCs increase by 6% each, while Heap Size remains unchanged.\\n3. Furthermore, CPU 85% spans increase by 10%.\\n4. Under Plutus workload however, there\'s just one significant observation: a larger portion of the heap is considered live (6% or ~190MB) with the overall Heap Size remaining constant.\\n\\nCaveat: Individual metrics can\'t be evaluated in isolate; the resource usage profile as a whole provides insight into the system\'s performance and responsiveness.\\n\\n### Forging Loop\\n\\n1. For the forger metrics, we can observe minor (1ms - 2ms) improvements in Ledger Ticking, Mempool Snapshotting and Self Adoption under value workload.\\n2. Under Plutus workload, there are minor (1ms - 2ms) increases in Ledger Ticking and Mempool Snapshotting.\\n\\nThe metric _\'Slot start to announced\'_ (see in attachments) is cumulative, and demonstrates how far into a slot the block producing node first announces the new header.\\n\\n### Peer propagation\\n\\n1. Block Fetch duration has improved by 11ms (or 3%) under value workload.\\n2. Under Plutus workload, peer Adoption times are slightly increased by 2ms (3%).\\n\\n### End-to-end propagation\\n\\nThis metric encompasses block diffusion and adoption across specific percentages of the benchmarking cluster, with 0.80 adoption meaning adoption on 80% of all cluster nodes.  \\n\\n1. Under value workload / full blocks, `9.2.0` exhibits a slight improvement of 1% - 3% in cluster adoption times.\\n2. Under Plutus workload / small blocks, there\'s a very minor increase by 1%.\\n\\n### Conclusion\\n\\n* We can not detect any perfomance regression in `9.2.0` compared to `9.1.1`.\\n* Under heavy value workload, `9.2.0` seems to perform work somewhat more eagerly. This would correlate with the slightly increased CPU usage, but also with the improvements in the forging and peer related metrics.\\n* The clearly increased efficiency of Block Fetch under heavy workload is the main contributing factor to the slight overall network performance improvement.\\n\\nNB. These benchmarks were performed using an adjusted, post-Chang hardfork performance baseline to account for added features in the Conway ledger era. Thus, absolute measurements might differ now from those taken using the previous baseline.\\n\\n## Contact\\n\\nAs for publishing such benchmarking results, we are aware that more context and detail may be needed with regard to specfic metrics or benchmarking methodology. \\n\\nWe are still looking to gather questions, both general and specific, so that we can provide a suitable FAQ and possibly improve presentation in the future.\\n\\n## Attachments\\n\\nFull report for _value-only workload_, PDF downloadable [here](../static/pdf/benchmarking/release-9.2.0.value-only.pdf).\\n\\nFull report for _Plutus workload_, PDF downloadable [here](../static/pdf/benchmarking/release-9.2.0.plutus.pdf)."},{"id":"2023-12-performance-8.7.2","metadata":{"permalink":"/reports/2023-12-performance-8.7.2","editUrl":"https://github.com/intersectmbo/cardano-updates/tree/main/reports/2023-12-performance-8.7.2.md","source":"@site/reports/2023-12-performance-8.7.2.md","title":"Benchmarking -- Node 8.7.2","description":"Setup","date":"2023-12-08T15:38:20.000Z","formattedDate":"December 8, 2023","tags":[{"label":"benchmarking-reports","permalink":"/reports/tags/benchmarking-reports"}],"readingTime":2.76,"hasTruncateMarker":false,"authors":[{"name":"Michael Karg","title":"Performance and Tracing Team Lead","url":"https://github.com/mgmeier","imageURL":"https://github.com/mgmeier.png","key":"mgmeier"}],"frontMatter":{"title":"Benchmarking -- Node 8.7.2","slug":"2023-12-performance-8.7.2","authors":"mgmeier","tags":["benchmarking-reports"],"hide_table_of_contents":false},"prevItem":{"title":"Benchmarking -- Node 9.2.0","permalink":"/reports/2024-09-performance-9.2.0"}},"content":"## Setup\\n\\nAs part of the release benchmarking cycle, we\'re comparing benchmarking runs for 3 different versions of `cardano-node`:\\n* `8.1.2` - the last mainnet release\\n* `8.7.0-pre` - as an intermediate reference point\\n* `8.7.2` - the next mainnet release\\n\\nFor each version, we\'re gathering various metrics under 2 different workloads:\\n1. _value-only_: Each transaction consumes 2 inputs and creates 2 outputs, changing the UTxO set. This workload produces full blocks (> 80kB) exclusively.\\n2. _Plutus_: Each transaction contains a Plutus script exhausting the per-tx execution budget. This workload produces small blocks (< 3kB) exclusively.\\n\\nBenchmarking is performed on a cluster of 52 block producing nodes spread across 3 different AWS regions, interconnected using a static, restricted topology. All runs\\nwere performed in the Babbage era.\\n\\n\\n## Observations\\n\\nThese benchmarks are about evaluating specific corner cases in a constrained environment that allows for reliable reproduction of results; they\'re not trying to directly recreate the operational conditions on Mainnet.  \\n\\nThe observations stated refer to the direct comparison between the `8.1.2` and `8.7.2` versions.\\n\\n### Resource Usage\\n\\n1. Plutus workload, having a lower overall absolute CPU load, exhibits an average increase of 27% in Process CPU usage. Value workload, having a higher overall absolute CPU load, exhibits a near-jitter increase of 1%.\\n2. Allocation rates increase by ~8.9MB/s (value workload) and ~12.6MB/s (Plutus workload).\\n3. Heap sizes increase by 47% - 54%.\\n4. CPU 85% span duration shrinks by ~9.7 slots under value workload, and ~5.8 slots under Pluts workload.\\n\\nCaveat: Individual metrics can\'t be evaluated in isolate; the resource usage profile as a whole provides insight into the system\'s performance and responsiveness.\\n\\n\\n### Forging Loop\\n\\n1. Block Context Acquisition in the forging loop increases by ~10ms.\\n2. Mempool snapshotting shows an increase by 16ms under value workload; under Plutus workload, it increases by 3ms.\\n3. Ledger ticking improves slightly by 1-2ms.\\n\\nThe metric _\'Slot start to announced\'_ (see in attachements) is cumulative, and demonstrates how far into a slot the block producing node first announces the new header.\\n\\n### Peer propagation\\n\\n1. Block fetch time increases for full blocks by 9%. For small blocks, it improves by 7%.\\n2. Time to resend a block after fetching increases by 8% for full blocks, whereas it improves by 2% for small blocks.\\n3. Block adoption by a peer takes 12% more time for a full block, but happens faster by 4% for a small block.\\n\\n### End-to-end propagation\\n\\nThis metric encompasses block diffusion and adoption across specific percentages of the benchmarking cluster, with 0.80 adoption meaning adoption on 80% of all cluster nodes.\\n\\nThe metric exhibits an increase by ~10% across all centiles for full blocks, whereas it improves by 5-6% for small blocks in the higher (80th and above) centiles.\\n\\n## Contact\\n\\nThis is the first time we\'re publishing, to a wider audience, such benchmarking results. We are aware that more context and detail may be needed with regard to specfic metrics or benchmarking methodology. \\n\\nWe are looking to gather questions, both general and specific, so that we can provide a suitable FAQ and possibly improve presentation in the future.\\n\\n## Attachments\\n\\nFull report for _value-only workload_, PDF downloadable [here](../static/pdf/benchmarking/8.7.1_8.1.2_8.7.0-pre_8.7.1-pre.value-only.pdf).\\n\\nFull report for _Plutus workload_, PDF downloadable [here](../static/pdf/benchmarking/8.7.1_8.1.2_8.7.0-pre_8.7.1-pre.plutus.pdf).\\n\\nThe relese benchmarks for `8.7.2` were performed on tag `8.7.1-pre`, which features identical `cardano-node` components."}]}')}}]);